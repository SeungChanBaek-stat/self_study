---
title: "고급회귀분석 5장"
output: html_document
date: "2025-03-18"
---

## 5.1 모형의 변환

### (예 5.1)
[표 3.1]에 있는 광고료와 판매액의 표본자료가 얻어진 모집단에 대하여 $\mu_{y \cdot x} = \beta_0 + \beta_1 x$ 가 성립된다고 가정하고 $\beta_1, \beta_0, \mu_{y \cdot x}$의 95% 신뢰구간을 구하시오.

```{r}
x = c(1,1,2,2,3,3,4,4,5,5) ; y = c(45,40,60,62,75,81,115,150,145,148) ; logy = log(y, base = 10)
```

```{r, echo=FALSE}
plot(x,y, xlab = "교육기간 (단위 : 주)x", ylab = "판매 성적 (계약건수)y",
     main = "보험 판매원 교육 자료", pch = 19, cex = 0.5)
```

```{r, echo = FALSE}
## y = alpha_0 * alpha_1^{x} * epsilon

X = data.frame(x, logy)

lm.fit = lm(logy ~ x, data = X)

summary(lm.fit)

beta_0_hat = lm.fit$coefficients[1] ; beta_1_hat = lm.fit$coefficients[2] 

alpha_0_hat = 10^{beta_0_hat} ; alpha_1_hat = 10^{beta_1_hat}

plot(x,y, xlab = "교육기간 (단위 : 주)x", ylab = "판매 성적 (계약건수)y",
     main = "보험 판매원 교육 자료", pch = 19, cex = 0.5)

curve(alpha_0_hat * alpha_1_hat^{x} , from = 1, to = 5, n = 101, add = TRUE, col = "lightblue")
```


```{r, echo = FALSE}
# 필요한 패키지 로드
library(ggplot2)

# 데이터 입력 및 로그 변환
x <- c(1,1,2,2,3,3,4,4,5,5)
y <- c(45,40,60,62,75,81,115,150,145,148)
logy <- log(y)

# 선형 모형 적합
lm.fit <- lm(logy ~ x)
beta0_hat <- coef(lm.fit)[1]
beta1_hat <- coef(lm.fit)[2]
alpha0_hat <- exp(beta0_hat)
alpha1_hat <- exp(beta1_hat)

# 데이터 프레임 생성
df <- data.frame(x = x, y = y)

# 적합 모형 함수를 정의 (원래 모형: y = alpha0 * alpha1^x)
fitted_func <- function(x) { alpha0_hat * alpha1_hat^x }

# ggplot으로 산점도 및 적합 곡선 그리기
ggplot(df, aes(x = x, y = y)) +
  geom_point(size = 2) +
  stat_function(fun = fitted_func, color = "blue", xlim = c(1, 5)) +
  labs(x = "교육기간 (단위 : 주)", y = "판매 성적 (계약건수)y",
       title = "보험 판매원 교육 자료") +
  theme_minimal()
```

```{r}
beta_0_hat ; beta_1_hat
alpha_0_hat ; alpha_1_hat
```

```{r}
plot(x,logy, xlab = "x", ylab = "logy",
     main = "변환된 회귀모형", pch = 19, cex = 0.5)

abline(coef = c(beta_0_hat, beta_1_hat), col = "lightblue")
```

```{r}
library(glue)
X_before = data.frame(x,y) ; X_after = data.frame(x,logy)
lm.fit_before = lm(y ~ x, data = X_before)
anova_before = anova(lm.fit_before)
SST_before = sum((y - mean(y))^{2}) ; SSE_before = anova_before$`Sum Sq`[2]

lm.fit_after = lm(logy ~ x, data = X_after)
anova_after = anova(lm.fit_after)
SST_after = sum((logy - mean(logy))^{2}) ; SSE_after = anova_after$`Sum Sq`[2]

R_sq_before =1 - SSE_before / SST_before ; R_sq_after =1 - SSE_after / SST_after 

print(glue("R_sq_before = {R_sq_before}, R_sq_after = {R_sq_after}"))
```

## 5.4 두 회귀선의 비교

### (예 5.2)

```{r, echo=FALSE}
x1 = c(100,125,220,205,300,255,225,175,270,170,155,190,140,290,265)
y1 = c(218,248,360,351,470,394,332,321,410,260,241,331,275,425,367)

x2 = c(105,215,270,255,175,135,200,275,155,320,190,295)
y2 = c(140,277,384,341,215,180,260,361,252,422,273,410)

# x, y 축 범위 설정
x_range <- range(c(x1, x2))
y_range <- range(c(y1, y2))

# 산점도 그리기: 생산라인1 (파란색, 원형)
plot(x1, y1, 
     pch = 19, col = "blue",
     xlab = "라인속도", ylab = "소모량", 
     xlim = c(x_range[1] - 10, x_range[2] + 10),
     ylim = c(y_range[1] - 10, y_range[2] + 10),
     main = "생산라인별 산점도")

# 산점도에 추가: 생산라인2 (빨간색, 삼각형)
points(x2, y2, 
       pch = 17, col = "red")

# 범례 추가
legend("topleft", 
       legend = c("생산라인 1", "생산라인 2"),
       col = c("blue", "red"), 
       pch = c(19, 17))
```

```{r, echo=FALSE}
# 데이터 프레임 생성 (각 데이터에 생산라인 구분 변수 추가)
df1 <- data.frame(라인속도 = x1, 소모량 = y1, 생산라인 = "생산라인 1")
df2 <- data.frame(라인속도 = x2, 소모량 = y2, 생산라인 = "생산라인 2")
df <- rbind(df1, df2)
df$생산라인 <- as.factor(df$생산라인)

# ggplot으로 산점도 그리기
ggplot(df, aes(x = 라인속도, y = 소모량, color = 생산라인, shape = 생산라인)) +
  geom_point(size = 3) +
  labs(title = "생산라인별 산점도", x = "라인속도", y = "소모량") +
  theme_minimal()
```

```{r}
x1 = c(100,125,220,205,300,255,225,175,270,170,155,190,140,290,265)
y1 = c(218,248,360,351,470,394,332,321,410,260,241,331,275,425,367)

x2 = c(105,215,270,255,175,135,200,275,155,320,190,295)
y2 = c(140,277,384,341,215,180,260,361,252,422,273,410)

## Full model

full_model.1 = lm(y1 ~ x1) ; full_model.2 = lm(y2 ~ x2)
anova.1 = anova(full_model.1) ; anova.2 = anova(full_model.2)

coef(full_model.1) ; coef(full_model.2)
anova.1 ; anova.2

SSE.1 = anova.1$`Sum Sq`[2] ; SSE.2 = anova.2$`Sum Sq`[2] 
SSE.F = SSE.1 + SSE.2 ; df.F = anova.1$Df[2] + anova.2$Df[2]
```

```{r}
## Reduced model
X = c(x1, x2) ; Y = c(y1, y2)
reduced_model = lm(Y ~ X)
anova.reduced = anova(reduced_model)

coef(reduced_model)
anova.reduced

SSE.R = anova.reduced$`Sum Sq`[2]
df.R = anova.reduced$Df[2]

F_0 = ((SSE.R - SSE.F) / (df.R - df.F)) / (SSE.F / df.F)
F_alpha = qf(0.05, df.R - df.F, df.F, lower.tail = FALSE)

print(glue("F_0 = {F_0}, F_alpha = {F_alpha}"))
```

### (예 5.3)

```{r}
beta1.1_hat = coef(full_model.1)[2] ; beta1.2_hat = coef(full_model.2)[2]

MSE.F = SSE.F / (df.F) ; S_xx.1 = sum((x1 -mean(x1))^{2}) ; S_xx.2 = sum((x2 -mean(x2))^{2})

var_hat = MSE.F * ((1/S_xx.1) + (1/S_xx.2))

t_0 = (beta1.1_hat - beta1.2_hat) / sqrt(var_hat)
t_alpha = qt(0.025, df.F, lower.tail = FALSE)

print(glue("t_0 = {t_0}, t_alpha = {t_alpha}"))
```


## 5.9 R 실습

### 5.9.1 두 회귀모형의 검정

$\textbf{맥주생산라인의 문제}$ [표 5.2]의 각 생산라인에서 얻어진 표본자료의 모집단에 대하여 각 두 회귀직선모형

\begin{equation*}
  y_{ij} = \beta_{0j} + \beta_{1j}x_{ij} + \epsilon_{ij} (i=1, \cdts, n_j, ~~j= 1,2)
\end{equation*}

이 성립된다고 가정하고 (예 5.2)와 (예 5.3)을 실습을 통해 풀어 보기로 한다.

먼저 (예 5.1)에서 살펴본 서로 다른 자료에 대한 두 회귀모형의 동일성 검정은 `gap`패키지의 `chow.test()`를 사용할 수 있다. [표 5.2]의 자료를 생성하여 불러온 결과는 다음과 같다.

```{r}
# install.packages("gap")
library(gap)

x1 = c(100,125,220,205,300,255,225,175,270,170,155,190,140,290,265)
y1 = c(218,248,360,351,470,394,332,321,410,260,241,331,275,425,367)
lab1 = c(rep("a", length(x1)))

x2 = c(105,215,270,255,175,135,200,275,155,320,190,295)
y2 = c(140,277,384,341,215,180,260,361,252,422,273,410)
lab2 = c(rep("b", length(x2)))

tab5_2 = data.frame(c(x1, x2), c(y1, y2), c(lab1, lab2))
colnames(tab5_2) = c("x", "y", "lab")

head(tab5_2)
```

`chow.test()`를 사용하기 위해서는 먼저 각 생산라인별로 다음과 같이 설명변수와 반응변수를 생성한다.

```{r}
y1 <- tab5_2[which(tab5_2$lab == 'a'), 2]
y2 <- tab5_2[which(tab5_2$lab == 'b'), 2]
x1 <- tab5_2[which(tab5_2$lab == 'a'), 1]
x2 <- tab5_2[which(tab5_2$lab == 'b'), 1]
chow.test(y1, x1, y2, x2)
```

이 결과로부터 각 생산라인별 라인 속도에 대한 맥주의 평균 소모량에 관한 회귀식이 유의수준 $\alpha = 0.05$에서 동일하지 않음을 알 수 있다.

### 5.9.2 두 기울기의 검정

이제 (예 5.3)에서 살펴본 것처럼 기울기가 같은지 검정해 보기로 한다. 이를 위하여 서로 다른 두 자료 `data1`, `data2`에 대하여 

\begin{equation*}
  t_0 = \cfrac{\hat{\beta}_{11} - \hat{\beta}_{12}}{\sqrt{\hat{\text{Var}} (\hat{\beta}_{11} - \hat{\beta}_{12})}}
\end{equation*}

를 검정통계량으로 사용하는 유의수준 $\alpha$ 검정을 하기 위한 `slope_test(data1, data2, alpha)`함수를 작성하면 다음과 같다.

```{r}
slope_test = function(data1, data2, alpha){
  n_1 = dim(data1)[1] ; n_2 = dim(data2)[1]
  
  xbar_1 = mean(data1$x) ; ybar_1 = mean(data1$y)
  S_xx_1 = sum((data1$x - xbar_1)^{2})
  S_xy_1 = as.numeric(t(data1$x - xbar_1) %*% (data1$y - ybar_1))
  beta1_1 = S_xy_1 / S_xx_1
  beta0_1 = ybar_1 - beta1_1 * xbar_1
  yhat_1 = beta0_1 + beta1_1 * data1$x
  SSE_1 = sum((data1$y - yhat_1)^{2})
  
  xbar_2 = mean(data2$x) ; ybar_2 = mean(data2$y)
  S_xx_2 = sum((data2$x - xbar_2)^{2})
  S_xy_2 = as.numeric(t(data2$x - xbar_2) %*% (data2$y - ybar_2))
  beta1_2 = S_xy_2 / S_xx_2
  beta0_2 = ybar_2 - beta1_2 * xbar_2
  yhat_2 = beta0_2 + beta1_2 * data2$x
  SSE_2 = sum((data2$y - yhat_2)^{2})
  
  SSEF = SSE_1 + SSE_2
  df_SSEF = (n_1 - 2) + (n_2 - 2)
  MSEF = SSEF / df_SSEF
  
  t_0 = (beta1_1 - beta1_2) / sqrt(MSEF * (1/S_xx_1 + 1/S_xx_2))
  critical_value = qt(alpha/2, df = df_SSEF, lower.tail = FALSE)
  
  if(abs(t_0) > critical_value){
    cat("Since |t_0| > t_", alpha/2, "(", df_SSEF, ")",
        " reject the null hypothesis.", "\n",
        "Here, |t_0| = ", abs(round(t_0, 3)), " and t_", alpha/2, "(", df_SSEF, ") = ",
        round(critical_value, 3), "\n", sep = "")
  }else{
    cat("Since |t_0| <= t_", alpha/2, "(", df_SSEF, ")",
        " there is not enough evidence to reject the null hypothesis.", "\n",
        "Here, |t_0| = ", abs(round(t_0, 3)), " and t_", alpha/2, "(", df_SSEF, ") = ",
        round(critical_value, 3), "\n", sep = "")
  }
}
```

이 함수를 사용하여 5.9.1 절에서 생성한 데이터로부터 두 기울기의 검정결과를 살펴 보면 (예 5.3)과 같은 결과를 얻는 것을 확인할 수 있다.

```{r}
line1 <- data.frame(x = x1, y = y1)
line2 <- data.frame(x = x2, y = y2)

slope_test(line1, line2, alpha = 0.05)
```

### 5.9.3 Box-Cox 변환에서의 $\lambda$ 결정

이제 Box-Cox 변환에서 $\lambda$를 결정하는 예제를 살펴보자. 먼저 다음과 같은 단순회귀모형을 생성하도록 한다.

```{r}
set.seed(1234)
n = 100 ; beta0 = 1 ; beta1 = 0.7

e = rnorm(n, mean = 0, sd = sqrt(0.1))
x = runif(n, min = 0, max = 5)
y = exp(beta0 + beta1 * x + e)

mydata = data.frame(x = x, y = y)
plot(y ~ x, data = mydata)
```

$log(y)$가 단순회귀모형 $(\beta_0 = 1, \beta_1 =0.7)$의 관계를 갖는 것으로, $\lambda = 0$에서 $(x,y)$가 생성되었다. 5.1.3절에서 $\lambda$를 결정하는 방법을 소개한 것처럼 멱변환 후 $SSE_{\lambda}$를 계산하는 `SSE_lambda()`함수를 생성해 보았다.

```{r}
SSE_lambda = function(x, y, lambda){
  
  if (lambda == 0){
    z_lambda = log(y) * prod(y)^{1/n}
  }else{
    z_lambda = (y^{lambda} - 1) / lambda * prod(y)^{(-1/n) * (lambda - 1)}
  }
  
  n = length(y)
  X = matrix(c(rep(1, n), x), n, 2)
  H = X %*% solve(t(X) %*% X) %*% t(X)
  I = diag(1, n)
  
  SSE_lambda = t(z_lambda) %*% (I - H) %*% z_lambda
  return(SSE_lambda)
}
```

위에서 생성한 함수를 이용하여, 일련의 lambda($\lambda$) 값에 대하여 `SSE_lambda()`함수값을 벡터화하는 함수 `vec_SSE_lambda()`를 작성하면, `lambda`를 [-2, 2]까지 0.2씩 변화시켜가며 `SSE_lambda`를 최소로 하는 최적의 lambda($\lambda$)를 찾을 수 있다.

```{r}
vec_SSE_lambda <- Vectorize(SSE_lambda, "lambda")
lambda <- seq(-2, 2, 0.2)
all_SSE <- vec_SSE_lambda(mydata$x, mydata$y, lambda)
(best_lambda <- lambda[which.min(all_SSE)])
(min_SSE <- all_SSE[which.min(all_SSE)])
```

위 결과를 보면 lambda = 0 일때 `SSE_lambda = 2159.1`로 최소가 되는 것을 알 수 있다. lambda를 [-2, 2]까지 0.2씩 변화하면서 이에 대응하는 log(SSE_lambda)값을 그려보면 다음과 같다.

```{r}
plot(lambda, log(all_SSE),
     type = "b", lwd = 2,
     xlab = "Lambda", ylab = "Sum of Squared Error(log-scale)")

points(x = best_lambda, y = log(min_SSE),
       col = "red", cex = 2, pch = 8)

```

### 더 큰 데이터셋의 경우

```{r}
set.seed(1234)
n = 1000 ; beta0_big = 1 ; beta1_big = 4

e_big = rnorm(n, mean = 0, sd = sqrt(0.1))
x_big = runif(n, min = 0, max = 10)
# y_big = 1 / (1 + exp(beta0_big + beta1_big * x_big + e_big))
y_big = beta0_big + beta1_big * (1/x_big) + e_big

mydata_big = data.frame(x = x_big, y = y_big)
plot(y_big ~ x_big, data = mydata_big)
```

```{r}
SSE_lambda_big = function(x, y, lambda){
  
  if (lambda == 0){
    z_lambda = log(y) * prod(y)^(1/n)
  }else{
    z_lambda = (y^{lambda} - 1) / lambda * prod(y)^{(-1/n) * (lambda - 1)}
  }
  
  n = length(y)
  X = matrix(c(rep(1, n), x), n, 2)
  H = X %*% solve(t(X) %*% X ) %*% t(X)
  I = diag(1, n)
  
  SSE_lambda = t(z_lambda) %*% (I - H) %*% z_lambda
  return(SSE_lambda)
}

vec_SSE_lambda_big <- Vectorize(SSE_lambda_big, "lambda")
lambda_big <- seq(-3, 3, 0.2)
all_SSE_big <- vec_SSE_lambda_big(mydata_big$x, mydata_big$y, lambda_big)
(best_lambda_big <- lambda_big[which.min(all_SSE_big)])
(min_SSE_big <- all_SSE_big[which.min(all_SSE_big)])
```

```{r}
plot(lambda_big, log(all_SSE_big),
     type = "b", lwd = 2,
     xlab = "Lambda", ylab = "Sum of Squared Error(log-scale)")

points(x = best_lambda_big, y = log(min_SSE_big),
       col = "red", cex = 3, pch = 19)
```

## 연습문제

### 5.1

```{r}
x = c(6.4,16.1,42.1,2.1,30.7,32.1,7.2,3.4,20.8,1.5)
y = c(1.7,2.7,4.9,0.3,3.9,4.1,1.2,0.5,3.3,0.2)

plot(x, y, xlab = "구매 상품의 금액 x (단위 : 천원)", ylab = "소요되는 시간 y (단위 : 분)",
     main = "슈퍼마켓 데이터", pch = 19, cex = 0.4)
```

```{r}
library(glue)

S_xx = sum((x-mean(x))^{2}) ; S_xy = sum( (x-mean(x))*(y-mean(y)) ) ; S_yy = sum((y-mean(y))^{2})
beta1_hat = S_xy / S_xx ; beta0_hat = mean(y) - beta1_hat * mean(x)
y_hat = beta0_hat + beta1_hat * x

SST = S_yy ; SSE = sum((y-y_hat)^{2}) ; SSR = SST - SSE

## (2)
r_squared = SSR/SST ; 
print(glue("r_squared = {r_squared}"))
print(glue("yhat = {beta0_hat} + {beta1_hat} x \n"))


## (3)
r_sq_calc = function(x, y){
  xbar = mean(x) ; ybar = mean(y)
  S_xx = sum((x-xbar)^{2}) ; S_xy = sum((x-xbar)*(y-ybar) ) ; S_yy = sum((y-ybar)^{2})
  beta1_hat = S_xy / S_xx ; beta0_hat = ybar - beta1_hat * xbar
  y_hat = beta0_hat + beta1_hat * x
  
  SST = S_yy ; SSE = sum((y-y_hat)^{2}) ; SSR = SST - SSE
  r_squared = SSR/SST ; r_squared
  return(list(r_squared = r_squared, beta1_hat = beta1_hat, beta0_hat = beta0_hat))
}

## (3)
y_a = log(y) ; result_a = r_sq_calc(x, y_a) ; r_sq_a = result_a$r_squared
x_b = sqrt(x) ; result_b = r_sq_calc(x_b, y) ; r_sq_b = result_b$r_squared
x_c = log(x, base = 10) ; y_c = log(y, base = 10) ; result_c = r_sq_calc(x_c, y_c) ; r_sq_c = result_c$r_squared
y_d = log(y, base = 10) ; result_d = r_sq_calc(x, y_d) ; r_sq_d = result_d$r_squared
x_e = 1/x ; result_e = r_sq_calc(x_e, y) ; r_sq_e = result_e$r_squared

print(glue("(a) r squared = {r_sq_a}, (b) r squared = {r_sq_b}, (c) r squared = {r_sq_c},
            (d) r squared = {r_sq_d}, (e) r squared = {r_sq_e}"))

## (4)
beta0_hat = result_b$beta0_hat ; beta1_hat = result_b$beta1_hat
y_hat_10 = beta0_hat + beta1_hat * sqrt(10) ; y_hat_10
```

### 5.2

```{r ,echo=FALSE}
y1 = c(28, 112, 160, 143, 156, 124) ; y2 = c(42, 136, 150, 161, 124, 104)
x = c(75, 100, 125, 150, 175, 200) ; x_ = rep(x, 2) ; y_ = c(y1, y2)

bank_data = data.frame(x_, y_)

plot(x_, y_, xlab = "x", ylab = "y", pch = 19, cex = 0.5)

## y = beta0 + beta1 x^2 + eps

x0 = c(rep(1, length(x_))) ; x1 = x_ ; x2 = x_^2
X = cbind(x0, x1, x2) ; y = y_

beta_hat = solve(t(X) %*% X) %*% t(X) %*% y
y_hat = X %*% beta_hat
SST = sum((y-mean(y))^2) ; SSE = sum((y-y_hat)^2) ; SSR = SST - SSE
r_squared = SSR/SST
print(glue("y_hat = {beta_hat[1]} + {beta_hat[2]} * x + {beta_hat[3]} * x^2"))
print(glue("r_squared = {r_squared}"))

## 적합결여검정
LF_test = function(fulldata_x, repeatdata_x, observed_y1, observed_y2,
                   alpha, SSE){
  
  n = length(fulldata_x) ; k = length(repeatdata_x)
  ybar_k = c(rep(0, k))
  for (i in 1:length(x)){
    ybar_k[i] = (observed_y1[i] + observed_y2[i])/2
  }
  
  SSPE = sum((observed_y1 - ybar_k)^{2}) + sum((observed_y2 - ybar_k)^{2})
  SSLF = SSE - SSPE
  print(glue("SSPE = {SSPE}, SSLF = {SSLF}, SSE = {SSE}"))
  F_0 = (SSLF/(k-2)) / (SSPE/(n-k))
  F_alpha = qf(alpha, k-2, n-k, lower.tail = FALSE)
  
  if(F_0 > F_alpha){
    print(glue("Since F_0 > F_{alpha}({k-2}, {n-k}), reject the null hypothesis. \n Here, F_0 = {round(F_0, 3)} and F_{alpha}({k-2}, {n-k}) = {F_alpha}"))
  }else{
    print(glue("Since F_0 <= F_{alpha}({k-2}, {n-k}), there is not enough evidence to reject the null hypothesis. \n Here, F_0 = {round(F_0, 3)} and F_{alpha}({k-2}, {n-k}) = {F_alpha}"))
  }
}


LF_test(x_, x, y1, y2, alpha = 0.05, SSE = SSE)

plot(x_, y_, xlab = "x", ylab = "y", pch = 19, cex = 0.5)
curve(beta_hat[1] + beta_hat[2] * x + beta_hat[3] * x^2 , from = 60, to = 200, n = 401, add = TRUE, col = "lightblue", lwd = 2.5)
```

### 5.3

#### 5.3 - (1)
```{r, echo = FALSE}
## (1)
x1 = c(seq(from = 10, to = 70, by = 10)) ; x2 = c(seq(from = 10, to = 70, by = 10))
y1= c(9.8, 12.5, 14.9, 16.5, 22.4, 24.1, 25.8) ; y2 = c(15.0, 14.5, 16.5, 19.1, 22.3, 20.8, 22.4)

# 산점도 그리기: 생산라인1 (파란색, 원형)
# x, y 축 범위 설정
x_range <- range(c(x1, x2))
y_range <- range(c(y1, y2))

plot(x1, y1, 
     pch = 19, col = "lightblue",
     xlab = "트럭 속도", ylab = "총 주행거리", 
     xlim = c(x_range[1] - 10, x_range[2] + 10),
     ylim = c(y_range[1] - 10, y_range[2] + 10),
     main = "타이어회사별 산점도")

# 산점도에 추가: 생산라인2 (빨간색, 삼각형)
points(x2, y2, 
       pch = 17, col = "red")

# 범례 추가
legend("topleft", 
       legend = c("타이어회사 1", "타이어회사 2"),
       col = c("lightblue", "red"), 
       pch = c(19, 17))
```

#### 5.3 - (2)

```{r, echo= FALSE}
y = c(x1, x2) ; x = c(y1, y2)
n1 = length(x1) ; n2 = length(x2)
lm1 = lm(y1 ~ x1) ; anova1 = anova(lm1)
lm2 = lm(y2 ~ x2) ; anova2 = anova(lm2)
lm_F = lm(y ~ x) ; anova_F = anova(lm_F) 

print(glue("y1_hat = {coef(lm1)[1]} + {coef(lm1)[2]}x1"))
print(glue("y2_hat = {coef(lm2)[1]} + {coef(lm2)[2]}x2"))
print(glue("y_hat = {coef(lm_F)[1]} + {coef(lm_F)[2]}x"))

SSE_1 = anova1$`Sum Sq`[2] ; SSE_2 = anova2$`Sum Sq`[2]
SSE_F = SSE_1 + SSE_2 ; SSE_R = anova_F$`Sum Sq`[2]
df_R = n1 + n2 - 2 ; df_F = (n1 - 2) + (n2 - 2)

F_0 = ((SSE_R - SSE_F) / (df_R - df_F)) / (SSE_F / df_F)
F_alpha = qf(0.05, df_R - df_F, df_F, lower.tail = FALSE)
print(glue("SSE_1 = {SSE_1}, SSE_2 = {SSE_2}, df_R = {df_R}, df_F = {df_F}"))
print(glue("SSE_F = {SSE_F}, SSE_R = {SSE_R}"))
print(glue("F_0 = {F_0}, F_alpha = {F_alpha}"))
```

#### 5.3 - (2)
```{r, echo = FALSE}
S_xx1 = sum((x1 - mean(x1))^2) ; S_xx2 = sum((x2 - mean(x2))^2)
beta11_hat = coef(lm1)[2] ; beta12_hat = coef(lm2)[2] ; MSE_F = SSE/(df_F)

t_0 = (beta11_hat - beta12_hat) / sqrt(MSE_F * (1/S_xx1 + 1/S_xx2))
t_alpha = qt(0.025, df_F, lower.tail = FALSE)

print(glue("|t_0| = {abs(t_0)}, t_alpha/2({df_F}) = {t_alpha}"))
```

### 5.8

```{r, echo=FALSE}
y = c(8.5, 8.4, 7.9, 8.1, 7.8, 7.6, 7.3, 7.0, 6.8, 6.7)
y1 = c(8.5, 7.9, 7.8, 7.3, 6.8) ; y2 = c(8.4, 8.1, 7.6, 7.0, 6.7)
x = c(seq(from = 0, to = 12, by = 3))
n = 10 ; k = 5 ; xbar = sum(2*x)/n ; T_i = y1 + y2
T = sum(T_i) ; ybar = T/n

S_xx= sum(2 * x^2) - (sum(2*x))^2 / n
S_yy = sum((y1)^2) + sum((y2)^2) - T^2 / n
S_xy = sum(x * T_i) - sum(2 * x) * T / n

SST = S_yy ; SSR = S_xy^2 / S_xx ; SSE = SST - SSR
print(glue("SST = {SST}, SSR = {SSR}, SSE = {SSE}"))

MSE = SSE / (n-2) ; MSR = SSR / 1

print(glue("F_0 = {MSR/MSE}, F_alpha = {qf(0.05, 1, n-2, lower.tail = FALSE)}"))

SSPE = sum((y1 - (T_i/2))^2) + sum((y2 - (T_i/2))^2) ; SSLF = SSE - SSPE

print(glue("SSPE = {SSPE}, SSLF = {SSLF}"))

MSPE = SSPE / (n-k) ; MSLF = SSLF / (k-2)

print(glue("F_0_LF = {MSLF/MSPE}, F_alpha = {qf(0.05, k-2, n-k, lower.tail = FALSE)}"))
```

### 5.11

```{r, echo = FALSE}
amazon = read.csv("amazon.csv")
Time = c(rep(1960, 8), rep(1970, 9))

dataset = data.frame(amazon, Time) ; dataset
```

#### 5.11 - (1)

```{r, echo=FALSE}
x_1960 = dataset[which(dataset$Time == 1960), 2]
x_1970 = dataset[which(dataset$Time == 1970), 2]

y_h_1960 = dataset[which(dataset$Time == 1960), 3]
y_h_1970 = dataset[which(dataset$Time == 1970), 3]

y_l_1960 = dataset[which(dataset$Time == 1960), 4]
y_l_1970 = dataset[which(dataset$Time == 1970), 4]

lm_h_1960 = lm(y_h_1960 ~ x_1960)
lm_h_1970 = lm(y_h_1970 ~ x_1970)
lm_l_1960 = lm(y_l_1960 ~ x_1960)
lm_l_1970 = lm(y_l_1970 ~ x_1970)


# par(mfrow = c(2,2))
plot(x_1960, y_h_1960, xlab = "연도", ylab = "1960년대 아마존강 최고수위",
     main = "연도에 따른 아마존강 최고수위", pch = 19, cex = 0.5)
abline(coef = coef(lm_h_1960))

plot(x_1970, y_h_1970, xlab = "연도", ylab = "1970년대 아마존강 최고수위",
     main = "연도에 따른 아마존강 최고수위", pch = 19, cex = 0.5)
abline(coef = coef(lm_h_1970))

plot(x_1960, y_l_1960, xlab = "연도", ylab = "1960년대 아마존강 최저수위",
     main = "연도에 따른 아마존강 최저수위", pch = 19, cex = 0.5)
abline(coef = coef(lm_l_1960))

plot(x_1970, y_l_1970, xlab = "연도", ylab = "1970년대 아마존강 최저저수위",
     main = "연도에 따른 아마존강 최저수위", pch = 19, cex = 0.5)
abline(coef = coef(lm_l_1970))

```

#### 5.11 - (2)

```{r}
library(glue)
## 최고수위의 경우
### 완전 모형 (full model)
anova_h_1960 = anova(lm_h_1960) ; anova_h_1970 = anova(lm_h_1970)
SSE_h_1960 = anova_h_1960$`Sum Sq`[2] ; SSE_h_1970 = anova_h_1970$`Sum Sq`[2]
df_h_1960 = anova_h_1960$Df[2] ; df_h_1970 = anova_h_1970$Df[2]

SSE_F_h = SSE_h_1960 + SSE_h_1970 ; df_F_h = df_h_1960 + df_h_1970

### 축소 모형 (reduced model)
y_h = c(y_h_1960, y_h_1970) ; x_h = c(x_1960, x_1970)
lm_h = lm(y_h ~ x_h)
anova_h = anova(lm_h)
SSE_R_h = anova_h$`Sum Sq`[2] ; df_R_h = anova_h$Df[2]

F_0 = ((SSE_R_h - SSE_F_h) / (df_R_h - df_F_h)) / (SSE_F_h / df_F_h)
F_alpha = qf(0.01, df_R_h - df_F_h, df_F_h, lower.tail = FALSE)

print(glue("F_0 = {F_0}, F_alpha = {F_alpha}"))
```
$F_0 = 9.468 > F_\alpha(df_R - df_F, df_F) = 6.701$ 이므로 귀무가설을 기각한다. 즉 1960년대와 1970년대의 아마존강 최고수위에 관한 회귀모형은 동일하다고 할 수 없다.

```{r}
library(glue)
## 최저수위의 경우
### 완전 모형 (full model)
anova_l_1960 = anova(lm_l_1960) ; anova_l_1970 = anova(lm_l_1970)
SSE_l_1960 = anova_l_1960$`Sum Sq`[2] ; SSE_l_1970 = anova_l_1970$`Sum Sq`[2]
df_l_1960 = anova_l_1960$Df[2] ; df_l_1970 = anova_l_1970$Df[2]

SSE_F_l = SSE_l_1960 + SSE_l_1970 ; df_F_l = df_l_1960 + df_l_1970

### 축소 모형 (reduced model)
y_l = c(y_l_1960, y_l_1970) ; x_l = c(x_1960, x_1970)
lm_l = lm(y_l ~ x_l)
anova_l = anova(lm_l)
SSE_R_l = anova_l$`Sum Sq`[2] ; df_R_l = anova_l$Df[2]

F_0_l = ((SSE_R_l - SSE_F_l) / (df_R_l - df_F_l)) / (SSE_F_l / df_F_l)
F_alpha_l = qf(0.01, df_R_l - df_F_l, df_F_l, lower.tail = FALSE)

print(glue("F_0 = {F_0_l}, F_alpha = {F_alpha_l}"))
```
$F_0 = 6.244 < F_\alpha(df_R - df_F, df_F) = 6.701$ 이므로 귀무가설을 기각할 수 없없다. 즉 1960년대와 1970년대의 아마존강 최저수위에 관한 회귀모형은 동일하다고 할 수 있다.

#### 5.11 - (3)

```{r}
S_xx1 = sum((x_1960 - mean(x_1960))^2) ; S_xx2 = sum((x_1970 - mean(x_1970))^2)

## 최고수위의 경우
beta11_hat_h = lm_h_1960$coefficients[2]; beta12_hat_h = lm_h_1970$coefficients[2]
var_hat_h = (SSE_F_h/df_F_h) * (1/S_xx1 + 1/S_xx2)

t_0 = (beta11_hat_h - beta12_hat_h) / sqrt(var_hat_h) ; t_alpha = qt(0.005, df_F_h, lower.tail = FALSE)

print(glue("유의수준 alpha = 0.01, 아마존강 최고수위의 경우 t_0 = {t_0}, t_alpha = {t_alpha}"))

## 최고수위의 경우
beta11_hat_l = lm_l_1960$coefficients[2]; beta12_hat_l = lm_l_1970$coefficients[2]
var_hat_l = (SSE_F_l/df_F_l) * (1/S_xx1 + 1/S_xx2)

t_0 = (beta11_hat_l - beta12_hat_l) / sqrt(var_hat_l) ; t_alpha = qt(0.005, df_F_l, lower.tail = FALSE)

print(glue("유의수준 alpha = 0.01, 아마존강 최저수위의 경우 t_0 = {t_0}, t_alpha = {t_alpha}"))
```
아마존강 최고수위의 경우 $|t_0| = 0.017 < t_\alpha(df_F) = 3.0122$으로, 귀무가설을 기각할 수 없다. 즉 유의수준 $\alpha = 0.01$에서 1960년대의 최고수위 증가량 수준과 1970년대의 최고수위 증가량 수준은 동일하다고 할 수 있다.

아마존강 최저수위의 경우 $|t_0| = 3.265 > t_\alpha(df_F) = 3.0122$으로, 귀무가설을 기각한다. 즉 유의수준 $\alpha = 0.01$에서 1960년대의 최저수위 증가량 수준과 1970년대의 최고수위 증가량 수준은 동일하다고 할 수 없다.