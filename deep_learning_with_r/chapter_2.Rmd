---
title: '2장 : 시작하기 전에, 신경망의 수학적 빌딩 블록'
output: html_document
date: "2025-11-18"

header-includes:
  - \newcommand{\bm}[1]{\boldsymbol{\mathbf{#1}}}
---
# 2장에서 다루는 내용

- 신경망의 첫번째 예제

- 텐서 및 텐서 연산

- 역전파 및 경사 하강을 통해 신경망을 학습하는 방법

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## 2.1 신경망 둘러보기

케라스 R 패키지를 사용한 손글씨 숫자를 분류하는 방법 
- 열 개 숫자로 된 손글씨(28 \times 28 픽셀)의 회색 음영 이미지를 열 개 범주(0~9)로 분류
- MNIST : 1980년대 미국 국립 표준 기술 연구소(NIST)에서 구성한 6만 개 훈련 이미지와 1만 개 테스트 이미지 집합

```{r}
# install.packages("reticulate")
# library(reticulate)
# use_condaenv("r-tf-env",
#              conda = 'C:/Users/PC/anaconda3/condabin/conda.bat',
#              required = TRUE)
# install.packages("tensorflow")
# install.packages("keras3")
library(tensorflow)
library(keras)

tf$config$list_physical_devices("GPU")  # GPU 인식 확인
```

```{r}
library(tensorflow)

tf$config$list_physical_devices()           # 전체 디바이스
tf$config$list_physical_devices("CPU")      # CPU
tf$config$list_physical_devices("GPU")      # GPU
tf$`__version__`
```

```{r}
library(tensorflow)

# 어떤 디바이스를 쓰는지 확인
tf$config$list_logical_devices()
```

### 목록 2.1 케라스에 내장된 MNIST 데이터셋 가져오기

```{r}
library(keras)
mnist = dataset_mnist()
train_images = mnist$train$x
train_labels = mnist$train$y
test_images = mnist$test$x
test_labels = mnist$test$y
```

```{r, echo=FALSE}
str(train_images)
str(train_labels)

str(test_images)
str(test_labels)
```

### 목록 2.2 신경망 아키텍처

```{r}
network = keras_model_sequential() %>%
  layer_dense(units = 512, activation = "relu", input_shape = c(28 * 28)) %>%
  layer_dense(units = 10, activation = "softmax")
```

### 목록 2.3 컴파일 단계

```{r}
network %>% compile(
  optimizer = "rmsprop",
  loss = "categorical_crossentropy",
  metrics = c("accuracy")
)
```

### 목록 2.4 이미지 데이터 준비하기

```{r}
train_images = array_reshape(train_images, c(60000, 28 * 28))
train_images = train_images / 255

test_images = array_reshape(test_images, c(10000, 28 * 28))
test_images = test_images / 255
```

### 목록 2.5 레이블 준비하기

```{r}
train_labels = to_categorical(train_labels)
test_labels = to_categorical(test_labels)
```

### 모델 훈련데이터 적합

```{r}
network %>% fit(train_images, train_labels, epochs = 5, batch_size = 128)
```

```{r}
metrics = network %>% evaluate(test_images, test_labels)
metrics
```

```{r}
network %>% predict(test_images[1:10,]) %>% k_argmax()
```

## 2.2 신경망에 대한 데이터 표현

텐서 : 임의의 차원 수로 이루어진 벡터 및 행렬의 일반화 개념

R에서 벡터는 1D 텐서를 만들고 조작하는 데 사용되며, 행렬은 2D 텐서에 사용된다.

더 상위인 차원의 경우, 임의의 수의 차원을 지원하는 배열 객체가 사용된다. 

### 2.2.1 스칼라

숫자가 한 개뿐인 텐서를 스칼라(scalar), 스칼라 텐서(scalar tensor), 0차원 텐서(zero-dimensional tensor) 또는 0D 텐서(0D 텐서)라고 한다. R에는 스칼라를 나타내는 데이터 유형이 없다(모든 숫자 객체는 벡터, 행렬 또는 배열임.) 그러나 항상 길이가 1인 R 벡터는 개념적으로 스칼라와 비슷하다.

### 2.2.2 벡터

1차원 배열로 구성된 수를 벡터(vector) 또는 1D 텐서(1D 텐서)라고 부른다. 1D 텐서는 정확히 하나의 축을 갖고 있다. R벡터를 배열 객체로 변환하면 차원을 확인해 볼 수 있다.

```{r}
x = c(12, 3, 6, 14, 10)
str(x)

dim(as.array(x))
```

### 2.2.3 행렬

숫자의 2차원 배열은 행렬(matrix), 즉 2D 텐서(2D tensor)이다. 행렬에는 행(raws)과 열(columns)이라 부르는 두 개 축이 있다. 행렬은 '직사각형 모양으로 된 숫자 격자'라는 식으로, 해석할 수 있다.

```{r}
x = matrix(rep(0, 3*5), nrow = 3, ncol = 5)
x

dim(x)
```

### 2.2.4 3D 텐서 및 고차원 텐서

새로운 행렬에 이러한 행렬들을 압축하면 시각적으로 정육면체라고 해석할 수 있는 3D 텐서를 얻을 수 있다.

```{r}
x = array(rep(0, 2*3*2), dim = c(2,3,2))
str(x)

dim(x)
```

배열에 3D 텐서를 꾸려 넣으면 4D 텐서를 생성할 수 있다. 딥러닝에서는 일반적으로 0D에서 4D까지의 텐서를 조작하지만, 비디오 데이터를 처리하는 경우, 5D까지 올라갈 수 있다.

### 2.2.5 주요 특성

텐서는 세 가지 주요 특성으로 정의된다.

- 축의 수(number of ranks) : 예를 들어, 3D 텐서에는 세 개축, 행렬에는 두 개 축이 있다.

- 모양(shapes) : 텐서가 각 축을 따라 몇 개 치수를 갖고 있는지를 나타내는 정수 벡터이다. 예를 들어, 앞의 행렬 예제는 (3, 5)모양이고, 3D 텐서 예제의 모양은 (2, 3, 2)이다. 벡터는 (5)와 같이 원소가 한 개뿐인 모양이다.

- 데이터 유형(data types) : 텐서에 포함된 데이터의 유형이다. 예를 들어, 텐서의 유형은 정수형(integer)이거나 배정도 실수형(double)일 수 있다. 드물기는 하지만, 문자형(character) 텐서를 볼 수도 있다. 그러나 텐서가 사전 할당된 인접 메모리 세그먼트에 있고, 가변 길이인 문자열은 이 구현의 사용을 배제하기 때문에 거의 사용되지 않는다.

#### 실제 MNIST 데이터셋의 예

```{r}
library(keras)
mnist = dataset_mnist()
train_images = mnist$train$x
train_labels = mnist$train$y
test_images = mnist$test$x
test_labels = mnist$test$y
```

```{r}
length(dim(train_images))

dim(train_images)

typeof(train_images)
```

```{r}
digit = train_images[5, , ]
plot(as.raster(digit, max = 255))
```

### 2.2.6 R에서 텐서 다루기

텐서 슬라이싱(tensor slicing) : 텐서에서 특정 원소를 선택하는 일

#### 10번에서 99번까지의 숫자 이미지를 선택하는 예

```{r}
my_slice = train_images[10:99, , ]
dim(my_slice)
```
```{r}
my_slice = train_images[10:99, 1:28, 1:28]
dim(my_slice)
```

#### 모든 이미지의 오른쪽 하단에 $14 \times 14$ 픽셀 선택의 예

```{r}
my_slice = train_images[, 15:28, 15:28]
dim(my_slice)
```

### 2.2.7 데이터 배치라는 개념

- 표본 축(sample axis) 또는 표본 차원(sample dimension) : 데이터 텐서의 첫 번째 축

- 딥러닝 모델은 학습 시에 전체 데이터셋을 한 번에 처리하기 보다, 작은 배치(batches)로 나눠서 처리한다.

- 배치 축(batch axis) 또는 배치 차원(batch dimension) : 배치 텐서를 고려했을 때의 첫 번째 축

```{r}
batch_1 = train_images[1:128, , ]
batch_2 = train_images[129:256, , ]

dim(batch_1)
dim(batch_2)
```

### 2.2.8 데이터 텐서의 실제 사례

- 벡터 데이터 : (표본, 특징) 모양으로 된 2D 텐서

- 일기 예보 데이터 또는 시퀀스 데이터 : (표본, 시간대, 특징) 모양으로 된 3D 텐서

- 이미지 : (표본, 높이, 너비, 채널) 모양 또는 (표본, 채널, 높이, 너비) 모양으로 된 4D 텐서

- 비디오 : (표본, 프레임, 높이, 너비, 채널) 모양 또는 (표본, 프레임, 채널, 높이, 너비) 모양으로 된 5D 텐서

### 2.2.9 벡터 데이터

가장 일반적인 데이터 텐서 종류로, 각 단일 데이터 점은 벡터로 부호화될 수 있으므로 데이터 배치는 2D 텐서(즉, 벡터 배열)로 부호화한다. 여기서 첫 번째 축은 표본 축(sample axis), 두 번째 축은 특징 축(feature axis)이다.

- 보험 통계 데이터셋 : 각 개인의 나이, 우편번호, 소득을 고려한 데이터셋. 각 사람은 세 가지 값의 벡터로 특징지을 수 있으므로 10만 명에 이르는 전체 데이터셋의 경우 (100000, 3) 모양으로 된 2D 텐서로 저장할 수 있다.

- 텍스트 문서 데이터셋 : 각 문서가 단어가 몇 번이나 등장하는지를 나타내는 데이터셋. 각 문서는 2만 개 값(사전에 들어 있는 한 개 단어당 한 개 값. 즉, 문서에는 그 단어의 출현 빈도수가 저장되어 있다.)으로 이뤄진 벡터로 부호화 될 수 있으므로 500개 문서로 된 전체 데이터 집합을 (500, 20000) 모양으로 된 텐서로 저장할 수 있다.

### 2.2.10 시계열 데이터 또는 시퀀스 데이터

데이터(또는 수열 순서의 개념)에서 시간이 중요할 때마다 명시적인 시간 축을 사용해 3D 텐서에 저장하는 게 바람직하다. 각 표본을 일련의 벡터(2D 텐서)로 부호화할 수 있으므로 데이터 배치는 3D 텐서로 부호화된다.

관례에 따라 시간 축은 항상 두 번째 축이다. 몇 가지 예를 살펴보자.

- 주가 데이터 셋 : 매분 주가의 현재 가격, 지난 1분간의 최고가 및 최저가로 저장된 데이터셋. 따라서 1분마다 크기가 3인 벡터가 되므로, 하루 동안 이뤄진 전체 거래는 (390, 3) 모양으로 된 2D 텐서(거래일에는 390분)으로 부호화되며, 250일분의 데이터를 (250, 390, 3) 모양으로 된 3D 텐서에 저장할 수 있다. 즉 여기에서의 각 표본은 하루 분량의 데이터가 된다.

- 트윗 데이터 셋 : 140개 크기를 가진 하나의 트윗에 대해, 128개 고유 영문자중 하나에 해당하는 경우 1, 그렇지 않으면 0을 부여하는 방식으로 크기가 128인 이진 벡터로 부호화할 수 있다. (one-hot encoding) 즉, 하나의 트윗에 대해 (140, 128) 크기의 2D 텐서로 부호화할 수 있으며, 100만 트윗의 데이터셋을 텐서 모양(1000000, 140, 128) 으로 저장할 수 있다.

### 2.2.11

일반적으로 이미지에는 높이(height), 너비(width) 및 색상 심도(color depth, 즉 색 깊이 또는 색심도)라는 세 가지 차원이 있다. 회색 음영 이미지(MNIST 숫자의 예)의 색상 채널은 한 개 뿐이므로 2D 텐서로 저장할 수 있지만, 이미지 텐서는 항상 3D이며, 회색조 (gray scale) 이미지에는 1차원 색상 채널이 있다. $256 \times 256$ 크기의 128개 회색조 이미지가 모인 배치 한 개는 (128, 256, 256, 1) 모양으로 된 텐서, 128개 색상 이미지로 이뤄진 배치 한 개는 (128, 256, 256, 3) 모양으로 된 텐서로 저장할 수 있다.

### 2.2.12

비디오 데이터는 5D 텐서가 필요한 몇 가지 유형의 실제 데이터 중 하나이다. 비디오는 프레임이 연달아 있는 형태로 이해할 수 있으며, 각 프레임은 컬러 이미지이다. 각 프레임은 3D 텐서(높이, 너비, 색상 심도)에 저장될 수 있고, 연속된 프레임은 4D 텐서 (프레임, 높이, 너비, 색상 심도)에 저장할 수 있다. 따라서 서로 다른 비디오들로 구성된 배치를 5D 텐서 모양(표본, 프레임, 높이, 폭, 색상 심도)에 저장할 수 있다.

## 2.3 신경망의 장비 : 텐서 연산

모든 컴퓨터 프로그램은 궁극적으로 이항 입력에 대한 작은 이항 연산(AND, OR, NOR 등)들로 구성된 집합으로 축소될 수 있으므로 심층 신경망에서 학습한 모든 변환도 텐서에 적용되는 소수의 수치 데이터에 관한 텐서 연산으로 줄일 수 있다. 예를 들어, 텐서를 더하거나 텐서를 곱하는 등의 작업을 할 수 있다.

```{r, eval = FALSE}
layer_dense(units = 512, activation = "relu")
```

이 계층은 2D 텐서를 입력으로 받아 다른 2D 텐서를 반환하는 함수로 해석될 수 있다. 구체적으로 함수는 다음과 같다.

```{r, eval = FALSE}
output = relu(dot(W, input) + b)
```

이 함수를 풀이해보면, input이라는 이름을 지닌 텐서와 $\mathbf{W}$라는 이름을 지닌 텐서사이의 내적(dot) 그리고 2D 텐서와 벡터 $b$ 사이의 덧셈(+), 마지막으로 렐루(ReLU)연산이라는 세 가지 텐서 연산이 있다. $\text{relu}(\mathbf{x}) = \text{max}(\mathbf{x}, 0)$이다.

### 2.3.1 원소별 연산

렐루 연산과 덧셈은 원소별(element-wise)연산이다. 즉, 텐서의 각 성분(entry, 즉 원소)에 독립적으로 적용되는 연산이다. 그러므로 이러한 작업은 대량 병렬 구현(벡터화된 구현, 1970~1990년의 벡터 프로세서를 사용하던 슈퍼컴퓨터 아키텍처에서 나온 용어)에 매우 적합하다.

원소 단위 연산을 단순하게 R로 구현하려면, 원소 단위 렐루 연산의 단순한 구현과 같이 `for` 루프를 사용해야 한다.
```{r}
# Generate a 4x4 matrix with random values from a standard normal distribution
x_mvn = matrix(rnorm(5 * 5), nrow = 5, ncol = 5)
y_mvn = matrix(rnorm(5 * 5), nrow = 5, ncol = 5)
print(x_mvn)
```

```{r}
naive_relu = function(x){
  for (i in 1:nrow(x)){
    for (j in 1:ncol(x)){
      x[i,j] = max(x[i,j], 0)
    }
  }
  return(x)
}

x_relu = naive_relu(x_mvn)
print(x_mvn)
print(x_relu)
```

덧셈도 같은 방식으로 처리한다.

```{r}
naive_add = function(x,y){
  for (i in 1:nrow(x)){
    for (j in 1:ncol(x)){
      x[i,j] = x[i,j] + y[i,j]
    }
  }
  return(x)
}

x_add = naive_add(x_mvn, y_mvn)
print(x_add)
```

같은 원리로 원소 단위로 곱셈과 뺄셈 등을 할 수 있다.

실제로는 R 배열들을 사용해 다룰 때, 최적화된 내장형 R 함수로 사용할 수 있는데, 이러한 내장 함수들은 무거운 작업을 BLAS 구현(Basic Linear Algebra Subprograms, 기본 선형 대수 서브프로그램)에 위임한다(따라서 BLAS를 설치해 둬야 한다). BLAS는 포트란 또는 C에서 일반적으로 구현되는 효율적인 저수준 병렬 처리 방식 텐서 조작 루틴이다.

R에서는 다음과 같이 원래의 원소별 연산들을 추종할 수 있으며, 연산들은 빠르게 처리될 것이다.

```{r}
z = x_mvn + y_mvn # 원소별 덧셈
print(z)
z = pmax(z, 0 ) # 원소별 렐루
print(z)
```

### 2.3.2 차원이 서로 다른 텐서와 관련된 연산

텐서의 덧셈시에, 두 개 텐서의 모양(shape)이 다른 경우, R의 `sweep()` 함수를 사용해 볼 수 있다.

R의 `sweep()`함수를 사용하면 더 높은 차원의 텐서와 낮은 차원의 텐서 간에 연산을 수행할 수 있다. `sweep()`을 사용하면 행렬에 벡터를 더하는 덧셈을 다음과 같이 수행할 수 있다.

```{r}
set.seed(42)
y_vec = matrix(rnorm(5), nrow = 5, ncol = 1)
# y_vec = as.vector(y_vec)
print(x_mvn)
print(y_vec)
sweep_ex = sweep(x_mvn, 1, y_vec, '+') # 여기서 2번째 인수는 y_vec을 스윕시킬 x_mvn의 차원을 지정한다.
print(sweep_ex)
```

여기서 2번째 인수는 y_vec을 스윕시킬 x_mvn의 차원을 지정한다. 마지막 인수(여기서는 +)는 스윕하는 중에 수행할 연산이며, 두 개 인수로 이루어진 함수여야 한다. 2번째 인수가 1이면 행에 대해서 y_vec을 주르륵 브로드캐스팅하여 덧셈, 2이면 열에 대해서 y_vec을 주르륵 브로드캐스팅하여 덧셈.

몇 개 차원이든 스윕 적용가능하며, 두 배열을 통해 벡터화된 연산을 구현하는 함수를 적용할 수 있다. 다음 예제는 `pmax()` 함수를 사용해 4D 텐서의 마지막 두 차원을 대상으로 2D 텐서를 스윕한다.

```{r}
x = array(round(runif(64* 3* 32* 10, 0, 9)), dim = c(64, 3, 32, 10))
y = array(5, dim = c(32, 10))

z = sweep(x, c(3,4), y, pmax)

print(dim(z))
# print(z[20, 1, , ])
```

### 2.3.3 텐서 내적

내적 연산은 텐서 곱(tensor product)이라고도 하며, (원소별 곱과 다른 개념이다)가장 일반적이고, 유용한 텐서 연산이다. 원소별 연산과 달리 입력 텐서의 성분을 결합한다.

R에서는 원소별 곱을 * 연산자로 처리하는 반면, 내적(dot products, 점곱)에는 %*% 연산자를 사용한다.

```{r}
x_vec = runif(10, -9, 9) ; y_vec = runif(10, -9, 9)
print(x_vec)
print(y_vec)
z = x_vec %*% y_vec
print(z)
```

```{r}
naive_vector_dot = function(x, y){
  z = 0
  for (i in 1:length(x)){
    z = z + x[[i]] * y[[i]] 
    # x[2] 는 x = (2,3,1,4,5)의 경우 (3)을 반환한다. 그러나 x[[2]]는 3을 반환한다. 즉 [[]] 연산자는 원소 그자체를 꺼낸다.
  }
  return(z)
}
z = naive_vector_dot(x_vec, y_vec)
print(z)
```

두 벡터 사이의 내적(dot product, 즉 스칼라 곱)은 스칼라이고, 원소 개수가 서로 같은 벡터만 내적과 호환된다는 것을 알 수 있다.

행렬 $\mathbf{x}$와 벡터 $\mathbf{y}$ 사이의 내적을 취할 수도 있다. 벡터는 $\mathbf{y}$와 $\mathbf{x}$ 의 행들 사이의 내적이 되는 벡터를 반환한다. 다음과 같이 구현할 수 있다.

```{r}
naive_matrix_dot = function(x, y){
  z = rep(0, nrow(x))
  for (i in 1:nrow(x)){
    for (j in 1:ncol(x)){
      z[[i]] = z[[i]] + x[[i,j]] * y[[j]]
    }
  }
  return(z)
}
set.seed(42)
x_mat = array(runif(40, -9, 9), dim = c(4,10))
z = naive_matrix_dot(x_mat, y_vec)
print(z)
print(typeof(z))
print(class(z))
```

```{r}
naive_matrix_dot = function(x, y){
  z = rep(0, nrow(x))
  for (i in 1:nrow(x)){
    z[[i]] = naive_vector_dot(x[i,], y)
  }
  return(z)
}
set.seed(42)
x_mat = array(runif(40, -9, 9), dim = c(4,10))
z = naive_matrix_dot(x_mat, y_vec)
print(z)
```

내적은 임의의 수의 축을 가진 텐서로 일반화되며, 이 경우 가장 일반적인 애플리케이션은 두 행렬 사이의 내적이라고 할 수 있다.

```{r}
naive_matrix_dot = function(x,y){
  z = matrix(0, nrow = nrow(x), ncol = ncol(y))
  for (i in 1:nrow(x)){
    for (j in 1:ncol(y)){
      row_x = x[i, ] ; col_y = y[,j]
      z[i, j] = naive_vector_dot(row_x, col_y)
    }
  }
  return(z)
}

set.seed(42)
x_mat = array(runif(20, -9, 9), dim = c(4,5))
y_mat = array(runif(10, -9, 9), dim = c(5,2))
z = naive_matrix_dot(x_mat, y_mat)
z_r = x_mat %*% y_mat
print(z == z_r)
```

더 일반적으로 2D 사례와 관련해서는 설명한 대로 모양 호환성에 대한 동일한 규칙에 따라 더 높은 차원의 텐서 간 내적을 가져올 수 있다.

```{r, eval = FALSE}
(a, b, c, d) . (d) -> (a, b, c)
(a, b, c, d) . (d, e) -> (a, b, c, e)
```

### 2.3.4 텐서 모양 변경

세 번째 유형의 텐서 연산은 텐서 모양 변경(tensor reshaping)이다. 텐서 모양 변경을 첫 번째 신경망 예제에 나오는 조밀 계층에 사용하지는 않았지만, 망에 입력하기 전, 숫자 데이터를 전처리할 때는 사용했었다.

```{r, eval = FALSE}
train_images = array_reshape(train_images, c(60000, 28 * 28))
```

`dim -< ()` 함수보다는 `array_reshape()` 함수를 사용해 배열의 모양을 변경한다는 점에 주목하자. 이는 행-중심 구문(row-major semantics)을 사용해 데이터가 재해석되도록 하기 위한 것으로 (R의 기본인 열 중심 구문과 반대), 한편으로 케라스가 호출한 수치 처리 라이브러리(NumPy 및 텐서플로 등)가 배열 차원을 해석하는 방식과 호환된다. 케라스에 전달될 R 배열을 다시 만들 때는 항상 `array_reshape()`함수를 사용해야 한다.

텐서 모양 변경이란, 행과 열을 표적의 모양과 일치하도록 재조정하는 것을 말한다. 당연히, 모양이 변경된 텐서에 사용하는 계수들의 총 개수는 초기 텐서와 동일해야 한다. 다음과 같은 예제를 통해 이러한 모양 변경을 가장 잘 이해할 수 있다.

```{r}
x = matrix(c(0, 1, 2, 3, 4, 5), nrow = 3, ncol = 2, byrow = TRUE)
x

x = array_reshape(x, dim = c(6,1))
x

x = array_reshape(x, dim = c(2,3))
x

```

흔히 발생하는 모양 변경의 특별한 경우는 전치(transpose)이다. 행렬의 전치는 `x[i, ]`가 `x[ ,i]`로 되도록 행과 열을 교환하는 것을 의미한다. 행렬을 전치하는 데는 `t()`함수를 사용할 수 있다.

```{r}
x = matrix(0, nrow = 300, ncol = 20)
dim(x)

x = t(x)
dim(x)
```

### 2.3.5 텐서 연산의 기하학적 해석

텐서 연산에 의해 조작된 텐서들의 내용은 어떤 기하 공간에서 점들의 좌표로 해석될 수 있기 때문에 모든 텐서 연산에는 기하학적 해석이 따른다.

일반적으로 어파인 변환, 회전, 척도 구성등과 같은 기본 기하 연산은 텐서 연산으로 표현될 수 있다. 예를 들어, 각도 $\theta$에 의한 2D 벡터의 회전은 $2 \times 2$행렬`R = [u,v]` 를 갖는 내적을 통해 이뤄질 수 있다. 여기서 `u`와 `v`는 평면의 벡터가 된다. 즉, `u = [cos(theta), sin(theta)]`, `v = [-sin(theta), cos(theta)]` 이다.

### 2.3.6 딥러닝의 기하학적 해석

신경망이 전적으로 텐서 연산의 연쇄(chains of tensor operations)로 구성되어 있고, 이러한 모든 텐서 연산이 입력 데이터의 기하학적 변환이라는 것을 알았다. 따라서 일련의 간단한 단계를 통해 구현된 고차원 공간에서 신경망을 매우 복잡한 기하학적 변환으로 해석할 수 있다.

(종이 공 예시).. 즉, 종이 공 펴기란, 복잡할 정도로 많이 접힌 데이터 다양하체(data manifolds)에 대한 깔끔한 표현을 찾는 머신러닝에 관한 것이다. 지금쯤이면 여러분은 딥러닝이 탁월한 이유를 잘 직감할 수 있어야 한다. 복잡한 기하학적 변환을 점진적으로 분해하여 기초 구성 요소들의 긴 연쇄로 만드는 접근 방식이 필요하다는 점 말이다. 이는 종이 공을 펼칠 때 인간이 따라야 할 전략과 거의 같다. 심층 망의 각 계층은 데이터를 약간 풀어 펴는 변형을 하는 역할을 하는 셈이 되고, 깊게 겹쳐 쌓인 각 계층들이 모여서 극도로 복잡한 펴기 과정을 다루기 쉽게 한다.

즉, 종이 공이 접힌 각도나 횟수, 모양에 맞게 신경망 모형의 계층을 구성한다면 적당한 양의 데이터가 주어졌을 때, 해당 종이 공을 펴지 않고도 무슨 종이로 구성되어있는지 매우 정확하게 맞출 수 있을 것이다. 반대로 계층을 적당하게 구성하지 못한다면 (계층수가 더 많거나 혹은 더 적거나, 계층안의 퍼셉트론수가 적거나 많거나 등등) 앞서의 신경망 모형의 경우보다 학습에 필요한 데이터양이 더 늘어날 수도 있으며, 혹은 학습 데이터양을 아무리 많이 늘리더라도 학습이 잘 되지 않을 수도 있다.


## 2.4 신경망의 엔진 : 경사 기반 최적화

핵심 개념 정리

```{r, eval = FALSE}
output = relu(dot(W, input) + b)
```

- 계층의 가중치 (훈련 가능 파라미터 ; trainable parameters)
  - W : 핵(kernel) 속성
  - b : 편향(bias, 바이어스 또는 치우침)
  
W와 b는 계층의 속성을 나타내는 텐서이다. 이는 신경망 모형의 각 계층별로 각기 다르게 존재하며, 신경망이 훈련 데이터에 노출되면서 학습한 정보가 들어있고, 학습을 할때마다 이 값이 업데이트 된다.

W와 b는 처음에 무작위(random) 값으로 초기화되며, 이 값은 신경망이 훈련데이터를 받아들일 때 나오는 피드백 신호에 따라 점진적으로 조정된다. 이러한 조정과정을 훈련(training)이라고 부른다. 구체적인 훈련 루프(training loop) 과정은 다음과 같다.

1. 훈련 표본 `x` 및 이에 상응하는 표적 `y`의 배치를 그린다.
2. 예측 경로 `y_pred`를 얻기 위해 `x`를 바탕으로 삼아 망을 실행한다. (forward propagation, 순방향전달)
3. `y_pred`와 `y`사이의 불일치를 측정한 배치에서 망 손실을 계산한다. (MSE, BCE 등 신경망 모형의 목적에 따라 여러 메트릭 존재)
4. 이 배치의 손실을 약간 줄이는 방식으로 망의 모든 가중치를 갱신한다. (SGD, Adam, RMSprop, AdaGrad, Muon, NAG 등)

즉, 위의 훈련 루프를 반복적으로 실행함으로써 훈련 데이터의 손실이 계속해서 줄어드는 방향으로 신경망 모형이 학습된다.

이로부터 훈련 데이터와 테스트 데이터의 분포가 일치한다는 가정하에, 실제 테스트 데이터에서도 예측 데이터 `y_pred`와 실제 표적 `y`간의 불일치가 줄어들게 됨을 기대할 수 있다. 이러한 논리는 전반적인 머신러닝 모델들에 대해 모두 적용된다.

1,2,3 단계는 I/O코드와 소수의 텐서 연산을 적용한 것뿐이므로 쉽게 구현 가능하다. 어려운 부분은 4단계로, 망에서 개별 가중 계수가 주어졌을 때 어떻게 계수를 키우거나 줄여야하는지가 관건이 된다.

개별 가중 계수의 갱신 방법은 지금도 연구되고 있는 분야이기도 하다. 현재까지의 정론은 경사하강법에 (gradient descent) 기반하여 갱신하는 방법이라고 할 수 있다. 즉, 망에서 사용되는 모든 연산이 미분 가능(differentiable)하다는 사실을 이용하여 망의 가중치와 관련해 손실의 경사(gradient)를 계산하는 것이다. 그런 다음, 가중치를 경사와 반대되는 방향으로 이동하면 손실을 줄일 수 있게 된다.

### 2.4.3 확률적 경사 하강

미분 가능 함수가 주어지면 이론적으로 손실 함수값 `loss = f(W)`을 해석적으로 찾아낼 수 있다. 손실 함수가 국소적으로 convex 하다는 가정하에, 이 함수의 최소값은 도함수 값이 0인 점이 되므로 도함수 값이 0이 되는 점들을 중 가장 낮은 값을 취하면 된다.

즉 신경망 모형에서는 가능한 한 손실 함수가 최소가 되게끔 하는 가중치 조합을 분석적으로 찾으면 되는 것이다. 이는 $\mathbf{W}$에 대한 등식 $\Delta f(W) = 0$ 을 구함으로써 수행할 수 있다. 이것은 $N$ 변량 다항식이 된다. 여기서 $N$은 망에 존재하는 계수들의 총 갯수가 되므로 $N=2,3$등 $N$이 작은 경우에는 방정식으로도 풀 수 있겠지만, 실제 신경망에서는 파라미터 수가 수천 개 이상, 혹은 수십, 수백만 개가 될 수도 있다.

따라서 해석적으로 해당 방정식을 푸는 대신에, 4단계 알고리즘을 사용하여 풀어 볼 수 있다.

각 파라미터의 경사를 계산하여, 다음과 같이 가중치를 경사와 반대되는 방향으로 갱신하면 손실이 조금씩 줄어들게 된다.

1. 훈련 표본들인 `x` 및 이에 상응하는 표적들인 `y`로 구성된 배치 한 개를 형성한다.
2. `y_pred` 예측을 얻기 위해 `x`를 이용해 망을 실행한다.
3. `y_pred`와 `y`사이의 불일치를 측정함으로써, 이 배치에 존재하는 망 손실을 계산한다.
4. 망의 파라미터들과 관련된 손실의 경사를 계산한다. (backpropagation, 역방향 전달)
5. 파라미터를 경사와 반대되는 방향으로 조금씩 이동한다. $(W = W - \text{step} * \cfrac{\partial L}{\partial W})$ 이를 통해 배치에 대한 손실이 약간 줄어들게 된다.

이러한 과정을 미니배치에 대한 확률적 경사 하강(minibatch stochastic gradient descent) 이라고 한다. 여기서 확률적(stochastic)이란 데이터의 배치가 무작위(random)로 선택된다는 것을 의미한다.

이때 step 인자에 대한 합리적인 값을 직관적으로 선택하는 것이 중요하다. 너무 작으면 손실 함수 곡선을 타고 내려오기 위해 많은 반복이 소요되며, 국소 최솟값(local minima)에서 멈출 수도 있다. 반대로 step이 너무 크게 되면 갱신이 끝날 때 곡선의 임의 위치로 이동할 수 있게 된다.

진정한 SGD의 경우, 주어진 미니배치 데이터 전체를 대상으로 삼아 반복처리하지 않으며, 단 한 가지 표본과 표적 단위로 반복 처리하게 된다. 또는 배치 SGD(batch SGD)의 경우 모든(all) 데이터를 대상으로 삼아 모든 단계를 실행하고 다시 반복하는 방식이 된다. 이러한 SGD 방식들은 각 갱신이 미니배치 SGD보다 더 정확하게 이뤄지나, 비용이 훨씬 비싸다. 이러한 두 극단의 SGD 사이의 효율적인 절충점은 합리적인 크기의 미니배치를 사용하는 것이라고 할 수 있다.

이러한 SGD 방식들 외에도, 경사의 현재 값을 보는 것이 아닌, 다음 가중치 갱신을 계산할 때 이전의 가중치 갱신을 고려해서 갱신 값을 달리하는 SGD의 변종들도 존재한다. 모멘텀을 적용하는 SGD를 비롯하여 Adagrad, RMSProp, Adam 등 여러 SGD 기반 방법들이 존재한다. 이러한 변종들은 최적화 기법(optimization methods)또는 최적화기(optimizer)로 알려져 있다.

특히 이러한 변종 중에 많은 변종에서 사용되는 모멘텀(momentum)이라는 개념에 주의를 기울여야 한다. 모멘텀은 SGD의 두 가지 문제, 즉 수렴 속도 및 국소 최솟값 문제들을 해결한다.

특정 파라미터 값 주변에는 국소 최솟값(local minimum)이 있으며, 그 지점의 주변에서 왼쪽으로 이동하거나 오른쪽으로 이동하거나 모두 손실이 증가하게 된다. 즉, 파라미터가 느린 학습 속도로 SGD를 통해 갱신 되는 경우, 갱신은 전역 최솟값(global minimum)대신에 국소 최솟값으로 이뤄지게 된다.

물리학에서 아이디어를 따온 모멘텀을 이용하면 이러한 문제를 피할 수 있다. 파라미터의 갱신 과정을 손실함수곡선을 따라 움직이는 작은 공으로 생각해보면 이해가 쉽다. 충분한 모멘텀하에, 공은 국소 최솟값이 자리 잡은 골짜기자리에 머물지 않고 전역 최소 수준에까지 움직일 수 있게 된다. 모멘텀기반 SGD는 현재 기울기 값(현재의 가속도)뿐 아니라 현재 속도(과거 가속도에서 나온 결과)를 기반으로 각 단계에서 파라미터가 갱신됨으로써 구현되며, 다음과 같이 현재의 경사 값뿐 아니라 이전 파라미터 갱신을 바탕으로 현재 파라미터를 갱신한다는 것을 의미한다.

```{r, eval=FALSE}
past_velocity = 0
momentum = 0.1
loss = 0.00
while (loss > 0.01){
  params = get_current_parameters()
  w = params$w
  loss = params$loss
  gradient = params$gradient
  
  velocity = past_velocity * momentum + learning_rate * gradient
  w = w + momentum * veleocity - learning_rate * gradient
  past_velocity = velocity
  
  update_parameter(w)
}
```

#### 파이프 연산자

```{r, eval=FALSE}
keras_model_sequential() %>% layer_dense(units = 512, activation = "relu", input_shape = c(28*28))

# 혹은

keras_model_sequential() %>% layer_dense(object = . , units = 512, activation = "relu", input_shape = c(28*28))
```

파이프연산자 : 왼쪽에 있는 오브젝트를 오른쪽 함수의 “첫번째” 입력값으로 넣는다 / 혹은 오른쪽 함수의 인수 중 넣고 싶은 부분에 대해 점(.)을 입력한다.


## 2.6 요약

- 학습은 주어진 학습 데이터의 표본 집합과 해당 표적에 대한 손실 함수를 최소화하는 모델 파라미터의 조합을 찾는 것을 의미한다.

- 학습은 데이터 표본과 표적의 무작위 배치들을 도출해 낸 후, 해당 배치상의 손실과 관련해 망 파라미터의 경사를 계산할 때 발생한다. 그런 다음, 망 파라미터가 경사의 반대 방향으로 약간 이동한다(학습 속도로 이동 속도를 정의한다).

- 학습이라고 하는 과정은 전반적으로, 신경망이 미분 가능 텐서를 사슬처럼 이어서 연산할 수 있기 때문에 가능해진 일이다. 따라서 현재 파라미터와 현재 데이터 배치를 경사 값에 사상하는 경사 함수를 찾기 위해 미분의 연쇄 법칙을 적용할 수 있다.

- 이후에 나오는 여러 장에서 자주 볼 수 있는 두 가지 주요 개념은 손실과 최적화기이다.
  - 손실은 훈련 중 최소화하려는 양이므로 해결하려는 작업의 성공 척도를 나타낸다.
  - 최적화기는 손실의 경사가 파라미터를 갱신하는 데 사용되는 정확한 방법을 지정한다. 예를 들어 RMSProp, Adagrad, Adam 등이 있다.