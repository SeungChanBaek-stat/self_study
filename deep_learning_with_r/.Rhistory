}
return(z)
}
z = naive_vector_dot(x_vec, y_vec)
print(z)
naive_vector_dot = function(x, y){
z = 0
for (i in 1:length(x)){
z = z + x[i] * y[i]
}
return(z)
}
z = naive_vector_dot(x_vec, y_vec)
print(z)
naive_matrix_dot = function(x, y){
z = rep(0, nrow(x))
for (i in 1:nrow(x)){
for (j in 1:ncol(x)){
z[[i]] = z[[i]] + x[[i,j]] * y[[j]]
}
}
return(z)
}
x_mat = array(runif(40, -9, 9), dim = c(4,10))
z = naive_matrix_dot(x_mat, y_vec)
print(z)
naive_matrix_dot = function(x, y){
z = rep(0, nrow(x))
for (i in 1:nrow(x)){
for (j in 1:ncol(x)){
z[[i]] = z[[i]] + x[[i,j]] * y[[j]]
}
}
return(z)
}
x_mat = array(runif(40, -9, 9), dim = c(4,10))
z = naive_matrix_dot(x_mat, y_vec)
print(z)
print(typeof(z))
naive_matrix_dot = function(x, y){
z = rep(0, nrow(x))
for (i in 1:nrow(x)){
for (j in 1:ncol(x)){
z[[i]] = z[[i]] + x[[i,j]] * y[[j]]
}
}
return(z)
}
x_mat = array(runif(40, -9, 9), dim = c(4,10))
z = naive_matrix_dot(x_mat, y_vec)
print(z)
print(typeof(z))
print(class(z))
naive_matrix_dot = function(x, y){
z = rep(0, nrow(x))
for (i in 1:nrow(x)){
for (j in 1:ncol(x)){
z[[i]] = z[[i]] + x[[i,j]] * y[[j]]
}
}
return(z)
}
x_mat = array(runif(40, -9, 9), dim = c(4,10))
z = naive_matrix_dot(x_mat, y_vec)
print(z)
print(typeof(z))
print(class(z))
print(dim(z))
naive_matrix_dot = function(x, y){
z = rep(0, nrow(x))
for (i in 1:nrow(x)){
for (j in 1:ncol(x)){
z[[i]] = z[[i]] + x[[i,j]] * y[[j]]
}
}
return(z)
}
x_mat = array(runif(40, -9, 9), dim = c(4,10))
z = naive_matrix_dot(x_mat, y_vec)
print(z)
print(typeof(z))
print(class(z))
print(shape(z))
naive_matrix_dot = function(x, y){
z = rep(0, nrow(x))
for (i in 1:nrow(x)){
for (j in 1:ncol(x)){
z[[i]] = z[[i]] + x[[i,j]] * y[[j]]
}
}
return(z)
}
x_mat = array(runif(40, -9, 9), dim = c(4,10))
z = naive_matrix_dot(x_mat, y_vec)
print(z)
print(typeof(z))
print(class(z))
naive_matrix_dot = function(x, y){
z = rep(0, nrow(x))
for (i in 1:nrow(x)){
for (j in 1:ncol(x)){
z[[i]] = z[[i]] + x[[i,j]] * y[[j]]
}
}
return(z)
}
set.seed(42)
x_mat = array(runif(40, -9, 9), dim = c(4,10))
z = naive_matrix_dot(x_mat, y_vec)
print(z)
print(typeof(z))
print(class(z))
naive_matrix_dot = function(x, y){
z = rep(0, nrow(x))
for (i in 1:nrow(x)){
for (j in 1:ncol(x)){
z[[i]] = z[[i]] + x[[i,j]] * y[[j]]
}
}
return(z)
}
set.seed(42)
x_mat = array(runif(40, -9, 9), dim = c(4,10))
z = naive_matrix_dot(x_mat, y_vec)
print(z)
print(typeof(z))
print(class(z))
naive_matrix_dot = function(x, y){
z = rep(0, nrow(x))
for (i in 1:nrow(x)){
z[[i]] = naive_vector_dot(x[i,], y)
}
return(z)
}
set.seed(42)
x_mat = array(runif(40, -9, 9), dim = c(4,10))
z = naive_matrix_dot(x_mat, y_vec)
print(z)
naive_matrix_dot = function(x, y){
z = rep(0, nrow(x))
for (i in 1:nrow(x)){
z[[i]] = naive_vector_dot(x[[i,]], y)
}
return(z)
}
set.seed(42)
x_mat = array(runif(40, -9, 9), dim = c(4,10))
z = naive_matrix_dot(x_mat, y_vec)
naive_matrix_dot = function(x, y){
z = rep(0, nrow(x))
for (i in 1:nrow(x)){
z[[i]] = naive_vector_dot(x[i,], y)
}
return(z)
}
set.seed(42)
x_mat = array(runif(40, -9, 9), dim = c(4,10))
z = naive_matrix_dot(x_mat, y_vec)
print(z)
naive_matrix_dot = function(x,y){
z = matrix(0, nrow = nrow(x), ncol = ncol(y))
for (i in 1:nrow(x)){
for (j in 1:ncol(y)){
row_x = x[i, ] ; col_y = y[,j]
z[i, j] = naive_vector_dot(row_x, col_y)
}
}
return(z)
}
set.seed(42)
x_mat = array(runif(20, -9, 9), dim = c(4,5))
y_mat = array(runif(10, -9, 9), dim = c(5,2))
z = naive_matrix_dot(x_mat, y_mat)
print(z)
print(x_mat %*% y_mat)
naive_matrix_dot = function(x,y){
z = matrix(0, nrow = nrow(x), ncol = ncol(y))
for (i in 1:nrow(x)){
for (j in 1:ncol(y)){
row_x = x[i, ] ; col_y = y[,j]
z[i, j] = naive_vector_dot(row_x, col_y)
}
}
return(z)
}
set.seed(42)
x_mat = array(runif(20, -9, 9), dim = c(4,5))
y_mat = array(runif(10, -9, 9), dim = c(5,2))
z = naive_matrix_dot(x_mat, y_mat)
z_r = x_mat %*% y_mat
print(z == z_r)
x = matrix(c(0, 1, 2, 3, 4, 5), nrow = 3, ncol = 2, byrow = TRUE)
x
x = array_reshape(x, dim = c(6,1))
x
x = array_reshape(x, dim = c(2,3))
x
x = matrix(c(0, 1, 2, 3, 4, 5), nrow = 3, ncol = 2, byrow = FALSE)
x
x = array_reshape(x, dim = c(6,1))
x
x = array_reshape(x, dim = c(2,3))
x
x = matrix(c(0, 1, 2, 3, 4, 5), nrow = 3, ncol = 2, byrow = TRUE)
x
x = array_reshape(x, dim = c(6,1))
x
x = array_reshape(x, dim = c(2,3))
x
x = matrix(0, nrow = 300, ncol = 20)
dim(x)
x = t(x)
dim(x)
knitr::opts_chunk$set(echo = TRUE)
# install.packages("reticulate")
# library(reticulate)
# use_condaenv("r-tf-env",
#              conda = 'C:/Users/PC/anaconda3/condabin/conda.bat',
#              required = TRUE)
# install.packages("tensorflow")
# install.packages("keras3")
library(tensorflow)
library(keras)
tf$config$list_physical_devices("GPU")  # GPU 인식 확인
library(tensorflow)
tf$config$list_physical_devices()           # 전체 디바이스
tf$config$list_physical_devices("CPU")      # CPU
tf$config$list_physical_devices("GPU")      # GPU
tf$`__version__`
library(tensorflow)
# 어떤 디바이스를 쓰는지 확인
tf$config$list_logical_devices()
library(keras)
mnist = dataset_mnist()
train_images = mnist$train$x
train_labels = mnist$train$y
test_images = mnist$test$x
test_labels = mnist$test$y
str(train_images)
str(train_labels)
str(test_images)
str(test_labels)
network = keras_model_sequential() %>%
layer_dense(units = 512, activation = "relu", input_shape = c(28 * 28)) %>%
layer_dense(units = 10, activation = "softmax")
network %>% compile(
optimizer = "rmsprop",
loss = "categorical_crossentropy",
metrics = c("accuracy")
)
train_images = array_reshape(train_images, c(60000, 28 * 28))
train_images = train_images / 255
test_images = array_reshape(test_images, c(10000, 28 * 28))
test_images = test_images / 255
train_labels = to_categorical(train_labels)
test_labels = to_categorical(test_labels)
network %>% fit(train_images, train_labels, epochs = 5, batch_size = 128)
metrics = network %>% evaluate(test_images, test_labels)
metrics
network %>% predict(test_images[1:10,]) %>% k_argmax()
x = c(12, 3, 6, 14, 10)
str(x)
dim(as.array(x))
x = matrix(rep(0, 3*5), nrow = 3, ncol = 5)
x
dim(x)
x = array(rep(0, 2*3*2), dim = c(2,3,2))
str(x)
dim(x)
library(keras)
mnist = dataset_mnist()
train_images = mnist$train$x
train_labels = mnist$train$y
test_images = mnist$test$x
test_labels = mnist$test$y
length(dim(train_images))
dim(train_images)
typeof(train_images)
digit = train_images[5, , ]
plot(as.raster(digit, max = 255))
my_slice = train_images[10:99, , ]
dim(my_slice)
my_slice = train_images[10:99, 1:28, 1:28]
dim(my_slice)
my_slice = train_images[, 15:28, 15:28]
dim(my_slice)
batch_1 = train_images[1:128, , ]
batch_2 = train_images[129:256, , ]
dim(batch_1)
dim(batch_2)
# Generate a 4x4 matrix with random values from a standard normal distribution
x_mvn = matrix(rnorm(5 * 5), nrow = 5, ncol = 5)
y_mvn = matrix(rnorm(5 * 5), nrow = 5, ncol = 5)
print(x_mvn)
naive_relu = function(x){
for (i in 1:nrow(x)){
for (j in 1:ncol(x)){
x[i,j] = max(x[i,j], 0)
}
}
return(x)
}
x_relu = naive_relu(x_mvn)
print(x_mvn)
print(x_relu)
naive_add = function(x,y){
for (i in 1:nrow(x)){
for (j in 1:ncol(x)){
x[i,j] = x[i,j] + y[i,j]
}
}
return(x)
}
x_add = naive_add(x_mvn, y_mvn)
print(x_add)
z = x_mvn + y_mvn # 원소별 덧셈
print(z)
z = pmax(z, 0 ) # 원소별 렐루
print(z)
set.seed(42)
y_vec = matrix(rnorm(5), nrow = 5, ncol = 1)
# y_vec = as.vector(y_vec)
print(x_mvn)
print(y_vec)
sweep_ex = sweep(x_mvn, 1, y_vec, '+') # 여기서 2번째 인수는 y_vec을 스윕시킬 x_mvn의 차원을 지정한다.
print(sweep_ex)
x = array(round(runif(64* 3* 32* 10, 0, 9)), dim = c(64, 3, 32, 10))
y = array(5, dim = c(32, 10))
z = sweep(x, c(3,4), y, pmax)
print(dim(z))
# print(z[20, 1, , ])
x_vec = runif(10, -9, 9) ; y_vec = runif(10, -9, 9)
print(x_vec)
print(y_vec)
z = x_vec %*% y_vec
print(z)
naive_vector_dot = function(x, y){
z = 0
for (i in 1:length(x)){
z = z + x[[i]] * y[[i]]
# x[2] 는 x = (2,3,1,4,5)의 경우 (3)을 반환한다. 그러나 x[[2]]는 3을 반환한다. 즉 [[]] 연산자는 원소 그자체를 꺼낸다.
}
return(z)
}
z = naive_vector_dot(x_vec, y_vec)
print(z)
naive_matrix_dot = function(x, y){
z = rep(0, nrow(x))
for (i in 1:nrow(x)){
for (j in 1:ncol(x)){
z[[i]] = z[[i]] + x[[i,j]] * y[[j]]
}
}
return(z)
}
set.seed(42)
x_mat = array(runif(40, -9, 9), dim = c(4,10))
z = naive_matrix_dot(x_mat, y_vec)
print(z)
print(typeof(z))
print(class(z))
naive_matrix_dot = function(x, y){
z = rep(0, nrow(x))
for (i in 1:nrow(x)){
z[[i]] = naive_vector_dot(x[i,], y)
}
return(z)
}
set.seed(42)
x_mat = array(runif(40, -9, 9), dim = c(4,10))
z = naive_matrix_dot(x_mat, y_vec)
print(z)
naive_matrix_dot = function(x,y){
z = matrix(0, nrow = nrow(x), ncol = ncol(y))
for (i in 1:nrow(x)){
for (j in 1:ncol(y)){
row_x = x[i, ] ; col_y = y[,j]
z[i, j] = naive_vector_dot(row_x, col_y)
}
}
return(z)
}
set.seed(42)
x_mat = array(runif(20, -9, 9), dim = c(4,5))
y_mat = array(runif(10, -9, 9), dim = c(5,2))
z = naive_matrix_dot(x_mat, y_mat)
z_r = x_mat %*% y_mat
print(z == z_r)
x = matrix(c(0, 1, 2, 3, 4, 5), nrow = 3, ncol = 2, byrow = TRUE)
x
x = array_reshape(x, dim = c(6,1))
x
x = array_reshape(x, dim = c(2,3))
x
x = matrix(0, nrow = 300, ncol = 20)
dim(x)
x = t(x)
dim(x)
past_velocity = 0
momentum = 0.1
while (loss > 0.01){
params = get_current_parameters()
w = params$w
loss = params$loss
gradient = params$gradient
velocity = past_velocity * momentum + learning_rate * gradient
w = w + momentum * veleocity - learning_rate * gradient
past_velocity = velocity
update_parameter(w)
}
past_velocity = 0
momentum = 0.1
loss = 0.00
while (loss > 0.01){
params = get_current_parameters()
w = params$w
loss = params$loss
gradient = params$gradient
velocity = past_velocity * momentum + learning_rate * gradient
w = w + momentum * veleocity - learning_rate * gradient
past_velocity = velocity
update_parameter(w)
}
input_tensor = layer_input(shape = c(784))
knitr::opts_chunk$set(echo = TRUE)
library(tensorflow)
library(keras)
knitr::opts_chunk$set(echo = TRUE)
library(tensorflow)
library(keras)
library(keras)
imdb = dataset_imdb(num_words = 10000)
c(c(train_data, train_labels), c(test_data, test_labels)) %<-% imdb
imdb = dataset_imdb(num_words = 10000)
train_data = imdb$train$x
train_labels = imdb$train$y
test_data = imdb$test$x
test_labels = imdb$test$y
max(sapply(train_data, max))
str(train_data[[1]])
train_labels[[1]]
str(train_data[[1]])
train_labels[[1]]
max(sapply(train_data, max))
max(sapply(train_data, max))
word_index = dataset_imdb_word_index()
reverse_word_index = names(word_index)
names(reverse_word_index) = word_index
decoded_review = sapply(train_data[[1]], function(index){
# 감상평 복호화. 0,1,2는 "채우기", "시퀀스 시작", "Unknown"을 나타내기 위해 예약된 인덱스 이므로 인덱스는 3만큼 오프셋된다.
word = if (index >= 3) reverse_word_index[[as.character(index - 3)]]
if (!is.null(word)) word else "?"
})
decoded_review
vectorize_sequences = function(sequences, dimension = 10000) {
results = matrix(0, nrow = length(sequences), ncol = dimension)
for (i in 1:length(sequences))
# 여기서 sequences[[i]] 는 train_data[[i]]에 해당하게 되며, 리스트 형태를 가지는 정수형 데이터가 된다.
# 앞서의 예와 같이 train_data[[1]]의 경우 int [1:218]로, 총 218개의 정수 원소를 가지는 리스트가 되어
# results의 1번째 행은 10000개의 열중 train_data[[1]]과 일치하는 218개의 열에 대해서만 1의 값을 가지고
# 나머지는 0이 되는 식으로 원핫 인코딩이 이뤄진다.
results[i, sequences[[i]] ] = 1
results
}
x_train = vectorize_sequences(train_data)
x_test = vectorize_sequences
str(x_train[1,])
vectorize_sequences = function(sequences, dimension = 10000) {
results = matrix(0, nrow = length(sequences), ncol = dimension)
for (i in 1:length(sequences))
# 여기서 sequences[[i]] 는 train_data[[i]]에 해당하게 되며, 리스트 형태를 가지는 정수형 데이터가 된다.
# 앞서의 예와 같이 train_data[[1]]의 경우 int [1:218]로, 총 218개의 정수 원소를 가지는 리스트가 되어
# results의 1번째 행은 10000개의 열중 train_data[[1]]과 일치하는 218개의 열에 대해서만 1의 값을 가지고
# 나머지는 0이 되는 식으로 원핫 인코딩이 이뤄진다.
results[i, sequences[[i]] ] = 1
results
}
x_train = vectorize_sequences(train_data)
x_test = vectorize_sequences(test_data)
knitr::opts_chunk$set(echo = TRUE)
library(tensorflow)
library(keras)
library(keras)
imdb = dataset_imdb(num_words = 10000)
c(c(train_data, train_labels), c(test_data, test_labels)) %<-% imdb
str(train_data[[1]])
train_labels[[1]]
max(sapply(train_data, max))
word_index = dataset_imdb_word_index()
reverse_word_index = names(word_index)
names(reverse_word_index) = word_index
decoded_review = sapply(train_data[[1]], function(index){
# 감상평 복호화. 0,1,2는 "채우기", "시퀀스 시작", "Unknown"을 나타내기 위해 예약된 인덱스 이므로 인덱스는 3만큼 오프셋된다.
word = if (index >= 3) reverse_word_index[[as.character(index - 3)]]
if (!is.null(word)) word else "?"
})
decoded_review
vectorize_sequences = function(sequences, dimension = 10000) {
results = matrix(0, nrow = length(sequences), ncol = dimension)
for (i in 1:length(sequences))
# 여기서 sequences[[i]] 는 train_data[[i]]에 해당하게 되며, 리스트 형태를 가지는 정수형 데이터가 된다.
# 앞서의 예와 같이 train_data[[1]]의 경우 int [1:218]로, 총 218개의 정수 원소를 가지는 리스트가 되어
# results의 1번째 행은 10000개의 열중 train_data[[1]]과 일치하는 218개의 열에 대해서만 1의 값을 가지고
# 나머지는 0이 되는 식으로 원핫 인코딩이 이뤄진다.
results[i, sequences[[i]] ] = 1
results
}
x_train = vectorize_sequences(train_data)
x_test = vectorize_sequences(test_data)
str(x_train[1,])
y_train = as.numeric(train_labels)
y_test = as.numeric(test_labels)
