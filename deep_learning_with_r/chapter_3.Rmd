---
title: '3장 : 신경망 입문'
output: html_document
date: "2025-11-24"
header-includes:
  - \newcommand{\bm}[1]{\boldsymbol{\mathbf{#1}}}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# 3장에서 다루는 내용

- 신경망의 핵심 구성 요소

- 케라스 소개

- 딥러닝 워크스테이션 설정

- 신경망을 사용해 기본적인 분류 및 회귀 문제 해결하기

## 3.1 신경망 해부학

신경망 훈련 구성 요소

- 망(network), 즉 모델(model)을 구성하는 계층(layers)

- 입력 데이터(input data)및 표적(targets)

- 학습에 사용된 피드백 신호를 정의하는 손실 함수(loss function)

- 학습이 어떻게 진행되는지를 결정하는 최적화기(optimizer)

망을 함께 연결하여 입력 데이터로부터 예측 값을 구하고, 손실 함수는 이러한 예측을 표적과 비교하여 손실 값을 산출한다. 망 예측이 예상했던 것과 얼마나 일치하는지를 측정하고, 최적화기는 손실 값을 통해 망의 가중치를 계산한다.


### 3.1.1 계층 : 딥러닝의 기본 요소

- 계층 : 하나 이상의 텐서를 입력으로 받아 하나 이상의 텐서를 출력하는 데이터 처리 모듈
  - 일부 계층은 상태가 비저장, 그 밖의 계층은 계층의 가중치들을 상태로 저장
  - 저장된 가중치를 확률적 경사 하강법등의 최적화기로 학습시키며, 이 가중치들에 망의 지식(knowledge)이 담긴다.
  
- 완전 연결 계층(fully connected layers, FC layers) 또는 조밀 계층(dense layers) : (표본, 특징) 모양으로 된 2D 텐서로 저장된 간단한 벡터 데이터에 적용

- 재귀 계층 (recurrent layers) : 3D 텐서 모양(표본, 시간대, 특징)에 저장된 시퀀스 데이터는 `layer_lstm` 등의 재귀 계층으로 처리된다.

- 합성곱 계층(convolutional layers) : 4D 텐서로 저장된 이미지 데이터는 2D 합성곱 계층 `layer_conv_2d`으로 처리된다.

계층은 딥러닝 전용 레고(LEGO) 블록이라고 생각할 수 있다. 이는 케라스와 같은 프레임워크에서 명시적으로 표현해둔 은유이다. 케라스의 딥러닝 모델 구축은 호환 가능한 계층을 오려내서 유용한 데이터 변환 통로를 형성하는 식으로 수행된다.

여기서 계층 호환성(layer compatibility)이라는 개념은 모든 계층이 특정 모양의 입력 텐서만 받아들이고, 특정 모양의 출력 텐서를 반환한다는 사실을 구체적으로 나타낸 개념이다.

케라스 사용시에는 모델에 추가하는 계층이 들어오는 계층의 모양과 일치하도록 동적으로 만들어지므로 호환성을 염려하지 않아도 된다. 예를 들어

```{r}
library(tensorflow)
library(keras)
```

```{r, eval=FALSE}
model = keras_model_sequential() %>% 
  layer_dense(units = 32, input_shape = c(784)) %>% 
  layer_dense(units = 32)
```

의 경우, 두번째 계층은 입력 모양 인수를 받지 못했으나, 입력 모양이 이전에 들어온 계층의 출력 모양(32)으로 유추된다.

### 3.1.2 모델 : 계층으로 이뤄진 망

딥러닝 모델이란, 방향성이 있고 순환하지 않는 그래프이다(DAG, Directed Acyclic Graph). 가장 쉬운 예로 단일 입력을 단일 출력으로 사상하도록 계층을 선형으로 쌓아올린 것을 생각할 수 있다.

그러나 이러한 이러한 예 외에 훨씬 다양한 네트워크 위상(network topologies)에 노출될 것이다. 다음과 같은 예들이 있다.

- 2분지 망(two-branch networks)
- 다중 헤드 망(multihead networks)
- 인셉션 블록(inception blocks)

네트워크 위상은 가설 공간을 정의하며, 네트워크 위상을 선택하게 되면 가능성의 공간(space of probabilities)을 일련의 특정 텐서 연산으로 제한하여 입력 데이터를 출력 데이터에 사상하게 된다. 이를 위해서는 텐서 연산에 관련된 가중치 소수점에 대한 좋은 값 집합을 찾아야 한다(무슨 소리인지 명확히는 이해못함).

적절한 망 아키텍처를 선택하는 일에는 과학이 아닌 예술이 필요하다(내가 어렴풋이 느끼던 딥러닝은 뭔가 과학이 아니라 아트같다는 느낌을 프랑소와 숄레 도 느끼고 있었다). 이러한 예술감각에는 몇 가지 모범 사례와 원칙이 있겠지만, 단지 연습만으로도 적절한 신경망 설계자가 될 수 있다.

### 3.1.3 손실 함수 및 최적화기 : 학습 과정을 구성하는 데 필요한 핵심 요소

망 아키텍처를 정의하고 나서도 두 가지를 더 선택해야 한다.

- 손실 함수(목적 함수) : 훈련하면서 최소화하는 양. 손실 함수는 당면 과제를 성공적으로 수행할 수 있는 메트릭이어야 한다.

- 최적화기 : 손실 함수에 따라 망을 갱신하는 방법을 결정한다. 최적화기는 확률적 경사 하강(SGD)의 특정 변형을 구현한다.

출력이 여러 개인 신경망에는 손실 함수가 여러 개 있을 수 있다(출력마다 하나씩). 그러나 경사 하강 과정은 단일 스칼라 손실 값을 기반으로 해야 한다. 따라서 다중 망의 경우, 모든 손실이 (평균화를 통해) 단일(single) 스칼라 수량으로 결합된다.

올바른 문제에 맞게 적절한 목적 함수를 선택하는 일은 매우 중요하다. 즉, 망은 손실을 최소화하기 위해 가능한 한 모든 지름길을 취한다. 따라서 목적이 현재 진행 중인 작업의 성공과 완전히 관련되지 않으면 망은 여러분이 원치 않는 일을 하게 된다(책에 훌륭한 예시가 있다). 따라서 객관적으로 봐서도 현명하다고 할 만한 손실 함수를 선택해야 하고 그렇게 하지 않는다면 의도하지 않은 부작용(side effects)에 직면할 수 있다.

다행히도 분류, 회귀 및 시퀀스 예측과 같은 일반적인 문제에 관해서 정확한 손실을 선택하기 위해 따라야만 하는 지침이 있다. 예를 들어, 2개 클래스로 분류하는 문제에 대한 이항 교차 엔트로피(BCE, binary cross entropy), 다중 클래스 분류 문제에는 범주적 교차 엔트로피(CCE, categorical cros entropy), 회귀 문제에는 평균제곱오차(MSE, mean squared error), 시퀀스 학습 문제에는 연결자 시간 분류(CTC, connectionist temporal classification) 등을 쓰면 될 것이다. 이러한 일반적인 문제가 아닌 새로운 연구 주제에 진심으로 골몰하는 경우에만 자신만의 목적에 맞는 손실 함수를 개발하면 될 것이다.

## 3.2 케라스 소개

케라스의 주요 기능

- 동일한 코드를 CPU에서나, GPU에서나 원활하게 실행할 수 있다.

- 사용자 친화 API를 사용하므로 딥러닝 모델을 신속하게 시범 제작해 볼 수 있다.

- 합성곱 망(컴퓨터 비전용), 재귀 망(시퀀스 처리용)및 이 두가지의 조합을 기본적으로 지원한다.

- 다중 입력 또는 다중 출력 모델, 계층 공유, 모델 공유 등 임의의 망 아키텍처를 지원한다. 

### 3.2.1 케라스, 텐서플로, 테아노 및 CNTK

케라스는 딥러닝 모델을 개발할 수 있는 고급 구성 요소를 제공하는 모델 수준 라이브러리이다. 텐서 연산 및 미분과 같은 저수준 연산은 처리하지 않는다. 그 대신, 케라스의 백엔드 엔진 역할을 하는 전문화되고 잘 최적화된 텐서 라이브러리에 의존한다.

케라스는 단일 텐서 라이브러리를 선택하고 그 라이브러리에 케라스 구현을 묶는 대신, 모듈 방식으로 문제를 처리한다. 따라서 여러 다른 백엔드 엔진을 케라스에 원활하게 연결할 수 있다(이후의 내용은 deprecated된 내용으로 생략한다).

테아노는 몬트리올 대학교 소속 MILA 연구소, 텐서플로는 구글, CNTK는 마이크로소프트에서 개발했다. 케라스로 작성한 모든 코드는 해당 코드에서 아무것도 변경하지 않은 채로 이러한 백엔드 중 하나를 선택하여 실행할 수 있다. 예를 들어, 이러한 백엔드 중 하나가 특정 작업에 더 빠르다는 게 증명되면 개발 중이더라도 두 가지 백엔드들 사이에서 원활하게 전환할 수 있다.

### 3.2.2 케라스 설치

케라스를 시작하려면 케라스 R 패키지, 핵심 케라스 라이브러리 및 백엔드용 텐서 엔진(예 : 텐서플로)을 설치해야 한다.

GPU를 활용하여 딥러닝 모델을 훈련하려면 텐서플로 백엔드 엔진의 GPU 기반 버전을 설치하는 것이 좋다.

```{r, eval=FALSE}
install_keras(tensorflow = "gpu")
```

그러나 이에 앞서 엔비디아 GPU 및 필수 소프트웨어(CUDA 및 cuDNN)이 있는 경우에만 위의 코드를 실행하는 것이 맞다.

### 3.2.3 케라스 이용 개발 : 훑어보기

일반적인 케라스 작업 흐름

1. 훈련 데이터 정의 (입력 텐서들과 표적 텐서들)

2. 입력을 표적에 사상하는 계층들로 이뤄진 망 정의

3. 손실 함수, 최적화기 및 관측할 일부 계량을 선택하여 학습 과정 구성

4. 모델의 `fit()` 메서드를 호출하여 훈련 데이터를 반복적으로 학습

모델을 정의하는 방법

- `keras_model_sequential()` 함수

```{r, eval=FALSE}
model = keras_model_sequential() %>% 
  layer_dense(units = 32, input_shape = c(784)) %>% 
  layer_dense(units = 10, activation = "softmax")
```

- 함수형 API

```{r, eval=FALSE}
input_tensor = layer_input(shape = c(784))
output_tensor = input_tensor %>% 
  layer_dense(units = 32, activation = "relu") %>% 
  layer_dense(units = 10, activation = "softmax")  

model = keras_model(inputs = input_tensor, outputs = output_tensor)
```

함수형 API를 사용하면 모델이 처리하는 데이터 텐서를 조작할 수 있고, 함수처럼 이 텐서에 계층을 적용할 수 있다.

모델 아키텍처가 정의되면, `keras_model_sequential()` 또는 함수형 API를 사용했는지 여부는 중요하지 않다. 다음에 나오는 단계들은 모두 동일하다.

학습 과정은 컴파일 단계에서 구성된다. 여기서 컴파일할 때 모델에서 사용해야 하는 최적화기 및 손실 함수와 훈련 중에 관측하려는 메트릭을 지정한다. 다음은 가장 일반적인 경우로서 단일 손실 함수를 사용한 예이다.

```{r, eval=FALSE}
model %>% compile(
  optimizer = optimizer_rmsprop(lr = 0.0001),
  loss = "mse",
  metrics = c("accuracy")
)
```

마지막으로 학습 과정은 입력 데이터의 배열(및 해당 표적 데이터의 배열)을 다른 머신러닝 라이브러리에서 수행하는 것과 비슷한 `fit()` 메서드를 통해 모델에 전달하는 것으로 구성된다.

```{r, eval=FALSE}
model %>% fit(input_tensor, target_tensor, batch_size = 128, epochs = 10)
```

## 3.3 딥러닝 워크스테이션 설정

CPU에서도 딥러닝 코드 실행이 가능하나, 망이 크고 복잡해질수록 GPU사용이 필수적이게 된다.

이 부분은 책이 쓰여진 시점(2019년)부터 상당히 오랜 기간이 지난 현재(2025년 11월) 시점에서 봤을 때 deprecated된 내용이 대다수이므로 그냥 가볍게 읽어보고 넘어가자. 딥러닝 워크 스테이션의 역사와 같다. 이 책이 쓰여진 시점의 나름 최신 GPU는 GTX 1060 시리즈였고, 현재는 RTX 5060까지 출시된 상황이다. 구글은 GPU를 전혀 활용하지 않고 자체 워크스테이션 하드웨어 장비인 TPU만으로 언어 모델 학습 및 추론에 성공하였다. 이렇게 보니까 기술의 발전속도가 경이롭긴 하다..

## 3.4 영화 감상평 분류 : 이항 분류 예제

두 개 클래스 분류, 즉 이항 분류(binary classification)는 가장 널리 적용되는 종류의 머신러닝 문제이다. 이번 예제에서는 감상평이 담긴 문장(text) 내용을 기준으로 영화 감상평을 긍정이나 부정으로 분류하는 방법을 배운다.

### 3.4.1 IMDB 데이터셋

IMDB 데이터셋으로 이진분류 문제를 풀어보고자 한다. 이 데이터셋은 인터넷 무비 데이터베이스(Internet Movie Database)라는 곳에서 가져온, 5만 편에 이르는, 아주 양극화된 감상평들을 모아둔 집합이다. 2만 5000개의 훈련용 감상평과 2만 5000개의 테스트용 감상평으로 나뉘어 있으며, 각 집합은 50%의 부정적인 감상평과 50%의 긍정적인 감상평으로 구성되어 있다.

위에서 알 수 있듯이, 이 데이터셋은 굉장히 쉬운, 달리 말하면 예제로 활용하기에 안성맞춤인 데이터셋이다. "아주 양극화된", "50%의 부정적, 50%의 긍정적" 데이터셋은 학습시키려는 모델이 무엇이던간에 이진분류시의 정확도가 잘 보장될 것이라는 것을 짐작할 수 있게 만든다. 실제 경진대회나 산업현장등에서 수집되는 데이터셋은 그렇지 못하기에, 피처 엔지니어링, 변수선택등 다양한 전처리방법을 먼저 적용한 다음 모델 학습을 하는게 맞다. 그렇지 않는다면 높은 정확도를 보장하는 모델 학습에 어려움을 겪을 수 있다.

그리고 이보다도 더 당연하지만 중요한 점은 테스트 데이터와 훈련 데이터의 분포가 동일해야 한다는 점이다. 그렇지 못하다면, 훈련데이터에서 높은 정확도를 달성한 모델이더라도, 테스트 데이터에서는 낮은 정확도를 보이게 될 수 있다. 이른바 일반화 오류(generalization error)가 커지게 된다. 이 책은 딥러닝 모델의 학습을 위주로 설명하는 책이다. 학습에 필요한 데이터가 무엇인지, 어떻게 데이터를 처리해줘야 하는지에 대해서는 언급하지 않는다. 사실 딥러닝 모델은 데이터의 패턴을 찾는데 특화되었기에, 일반적인 머신러닝 모델과 달리 전처리가 그닥 필요하지 않을 수도 있다. (특히 이미지와 같은 비정형데이터의 경우 더욱 그러하다)

내 생각에, 정형데이터의 경우는 아직까지 딥러닝 모델이 만능은 아니기에, 데이터 전처리는 여전히 중요하다. 또한 정형 데이터나 비정형 데이터의 경우 모두, 훈련 데이터와 테스트 데이터의 분포가 서로 거의 동일해야 딥러닝 모델이든 머신러닝 모델이든 일반화 오류율을 줄일 수 있다. 이게 가장 기본적인 지도학습의 개념이기도 하다. 이 책에서 언급하는 "모델이 훈련용 표본 데이터와 표적 간의 대응 관계만 기억하게 할 수도 있지만, 이렇게 하면 모델은 신규 데이터를 가지고 표적을 예측하지 못 하게 된다"는 말은 과적합을 의미하는 것으로 보인다. 이러한 과적합이 일어나게 되면 일반화 오류율이 상승한다. 이를 막기 위해 가장 일반적인 방법은 early stopping이 된다. 즉 일반화 오류율이 가장 작은 지점에서 훈련을 인위적으로 멈추고 학습된 가중치로 테스트 데이터에 대한 예측이나 추론을 하는 방법이다. 이 방법은 적은 컴퓨팅 소요 단위에 비해 어느정도 좋은 성능을 보장해주므로 cost-efficient한 방법이라고 생각한다.

그러나 만약 훈련 데이터와 테스트 데이터의 분포가 정말로 동일하다면, 과적합이 순간적으로 일어날지라도 모델이 계속해서 학습을 하게 될때, 일반화 오류율이 다시 줄어들기 시작하는 현상이 발생할 수 있다(앞서 early stopping 했을 때보다 더 낮은 일반화 오류를 가지는 경우도 존재한다!). 이러한 현상을 double descent라고 부르며, 딥러닝 모델에서는 grokking 현상이 일어난다고 표현하기도 한다. 물론 어떤 조건하에서 이러한 현상이 일어나는지는 아직까지 구체적인 게 전부 밝혀지지는 않았고 계속해서 연구되는 분야이기도 하다. 내 표현으로 하자면, 모델이 enlighten 되는 순간이 grokking 이라고 할 수 있을 것 같다.


다시 돌아와서, IMDB 데이터셋을 불러와보자. 이 데이터셋은 전처리된 상태이며, 감상평(단어 시퀀스)은 정수 시퀀스로 바뀌어 있다. 여기서 각 정수는 사전의 특정 단어를 나타낸다.

#### 목록 3.1 : IMDB 데이터셋 적재하기

```{r}
library(keras)

imdb = dataset_imdb(num_words = 10000)
c(c(train_data, train_labels), c(test_data, test_labels)) %<-% imdb 
```

#### 다중 할당( %<-% ) 연산자 사용하기

케라스에 내장된 모든 데이터셋에는 훈련 데이터와 테스트 데이터가 다 들어 있다. 여기서 우리는 zeallot 패키지의 다중 할당 연산자( %<-% )를 사용해 목록을 다른 변수 집합으로 압축한다. 다중 할당 연산자를 사용하지 않고 이 작업을 수행하려면 필요한 코드는 아마도 다음과 같을 것이다.

```{r, eval=FALSE}
imdb = dataset_imdb(num_words = 10000)
train_data = imdb$train$x
train_labels = imdb$train$y
test_data = imdb$test$x
test_labels = imdb$test$y
```

여기서 인수 `num_words = 10000`은 훈련 데이터에서 출현 빈도를 기준으로 상위 1만 개 단어만 유지한다는 것을 의미한다. 어쩌다가 한 번씩 쓰인 단어는 삭제된다. 이렇게 희박하게 나타나는 단어를 제외하면 처리 용량에 맞춰 벡터 데이터를 구성할 수 있다.

변수 `train_data`와 `test_data`는 감상평을 담은 리스트이다. 각 감상평은 단어 인덱스 리스트(단어 시퀀스로 부호화한 것)이고, `train_labels`와 `test_labels`는 0과 1로 구성된 리스트이다. 여기서 0은 부정, 1은 긍정을 나타낸다.

```{r}
str(train_data[[1]])

train_labels[[1]]
```

가장 자주 사용되는 상위 1만 개 단어로 제한하고 있으므로 단어 인덱스는 10,000을 초과하지 않는다.

```{r}
max(sapply(train_data, max))
```

예를 들어 다음 감상평 중 하나를 영어 단어로 빠르게 복호화(decode)하는 방법은 다음과 같다.

```{r}
word_index = dataset_imdb_word_index()
reverse_word_index = names(word_index)
names(reverse_word_index) = word_index
decoded_review = sapply(train_data[[1]], function(index){
  # 감상평 복호화. 0,1,2는 "채우기", "시퀀스 시작", "Unknown"을 나타내기 위해 예약된 인덱스 이므로 인덱스는 3만큼 오프셋된다.
  word = if (index >= 3) reverse_word_index[[as.character(index - 3)]]
  if (!is.null(word)) word else "?"
})

decoded_review
```

### 3.4.2 데이터 준비

정수 리스트를 신경망에 공급(feed)할 수 없으므로 텐서로 변환해야 한다. 이에 대한 방법으로 책에서는 2가지를 제시한다.

- 리스트가 같은 길이가 되도록 채우기를 하고, (표본들, 단어_색인들) 모양으로 된 정수 텐서로 변환한 후 망의 첫 번째 계층으로 이러한 정수 텐서를 처리할 수 있는 계층을 사용한다.

- 리스트를 원핫 인코딩(one-hot encoding)으로 처리하여 0과 1로 된 벡터로 바꾼다. 예를 들어 시퀀스 `[3, 5]`를 1이 들어가는 인덱스 3과 5자리를 제외한 나머지 자리가 모두 0이 들어가는 1만 차원의 벡터로 바꾸는 것을 의미한다. 그런 다음, 망에서 부동 소수점 벡터 데이터를 처리할 수 있는 조밀 계층을 첫 번째 계층으로 사용할 수 있다.

여기서는 두 번째 방법을 사용하여 데이터를 벡터화하되, 명료하게 이해할 수 있게 일일이 직접 해 보자.

#### 목록 3.2 정수 시퀀스를 이진 행렬로 부호화

```{r}
vectorize_sequences = function(sequences, dimension = 10000) {
  results = matrix(0, nrow = length(sequences), ncol = dimension)
  for (i in 1:length(sequences))
    # 여기서 sequences[[i]] 는 train_data[[i]]에 해당하게 되며, 리스트 형태를 가지는 정수형 데이터가 된다.
    # 앞서의 예와 같이 train_data[[1]]의 경우 int [1:218]로, 총 218개의 정수 원소를 가지는 리스트가 되어
    # results의 1번째 행은 10000개의 열중 train_data[[1]]과 일치하는 218개의 열에 대해서만 1의 값을 가지고
    # 나머지는 0이 되는 식으로 원핫 인코딩이 이뤄진다.
    results[i, sequences[[i]] ] = 1
  results
}

x_train = vectorize_sequences(train_data)
x_test = vectorize_sequences(test_data)
```

```{r}
str(x_train[1,])
```

레이블을 정수에서 숫자로 변환하는 방법은 다음과 같다.

```{r}
y_train = as.numeric(train_labels)
y_test = as.numeric(test_labels)
```

### 3.4.3 망 구축

입력 데이터는 벡터이며 레이블은 스칼라(1과 0)이다(가장 흔히 쓰이는 구성방식). 이러한 문제를 잘 수행하는 망 유형은 ReLU 활성을 사용하는 완전 연결(조밀) 계층들을 단순하게 겹쳐 쌓기만 한 스택이다.

```{r, eval=FALSE}
layer_dense(units = 16, activation = "relu")
```

각 조밀 계층에 전달되는 인수는 계층의 은닉 유닛 수(16)이다. 은닉 유닛(hidden unit)은 계층의 표현 공간에 있는 차원이다. 2장에서 ReLU 활성화 구현이 있는 이러한 조밀 계층이 다음과 같은 일련의 텐서 연산을 구현한다는 것을 기억할 것이다.

```{r, eval=FALSE}
output = relu(dot(W, input) + b)
```

16개의 은닉 유닛을 가짐으로써 `W`가 `(입력_차원, 16)` 모양으로 된 가중치 행렬을 가짐을 의미한다. `W` 가 있는 내적은 입력 데이터를 16차원 표현 공간에 정사영한다(그런 다음, 편향 벡터 `b`를 추가하고, ReLU 연산을 적용한다). 표현 공간의 차원은 직관적으로 "내부 표현을 학습할 때 망이 가질 수 있는 자유의 정도"라는 식으로 이해할 수 있다. 더 많은 은닉유닛(더 높은 차원의 표현 공간)을 사용하면 망보다 복잡한 표현을 학습할 수 있지만, 망 계산 비용이 많이 들고, 원치 않는 패턴(훈련 데이터에서는 성능이 향상되는 패턴이지만, 테스트 데이터에서는 그렇지 않은 패턴)을 학습하게 될 수도 있다.

이러한 조밀 계층 스택에는 두 가지 주요 아키텍처 결정이 필요하다.

- 사용할 계층 수
- 계층별로 선택할 은닉 유닛 수

여기서 다루는 활성 함수는 다음과 같다. 중간 계층은 ReLU, 맨 끝 계층은 시그모이드를 활성함수로 사용하여 확률을 출력한다.

- ReLU : 정류된 선형 유닛(rectified linear unit) 은 $f(x) = \text{max}(x,0)$ 의 함수로, 음인 값들을 0으로 만드는 함수이다.
- Sigmoid : 시그모이드(sigmoid)는 $f(x) = \cfrac{1}{1+ e^{-x}}$의 함수로, 임의의 값을 $[0, 1]$ 구간으로 크게 축소함으로써 확률로 해석해 볼 여지가 있는 수치 형태로 출력한다(여기서 "확률로 해석해 볼 여지가 있는"에 주목해야 한다. 엄밀한 의미에서 시그모이드 값은 확률이라고 할 수는 없다.).

#### 목록 3.3 모델 정의하기

```{r}
library(keras)

model = keras_model_sequential() %>% 
  layer_dense(units = 16, activation = "relu", input_shape = c(10000)) %>% 
  layer_dense(units = 16, activation = "relu") %>% 
  layer_dense(units = 1, activation = "sigmoid")
```

마지막으로, 손실 함수와 최적화기를 선택해야 한다. 왜냐하면 지금 이항 분류 문제를 다루고 있는데, 현재의 망은 확률의 꼴로 출력하기 때문에 `binary_crossentropy`라는 손실 함수를 사용하는 편이 가장 바람직하다. 이는 유일하게 실행할 수 있는 선택이 아니다. 예를 들어, `mean_squared_error`가 그렇다. 하지만 교차 엔트로피는 일반적으로 확률을 산출하는 모델을 다룰 때 가장 좋은 선택이다. 교차 엔트로피는 정보 이론 분야에서 확률분포 사이의 거리를 측정하는 양이며, 이 경우에는 실제 분포와 예측 분포 사이의 거리를 측정한다.

#### 목록 3.4 모델 컴파일하기

```{r}
model %>% compile(
  optimizer = "rmsprop",
  loss = "binary_crossentropy",
  metrics = c("accuracy")
)
```

위의 모델 컴파일시에, 함수의 인수로서 사용자 정의 손실 함수나 메트릭 함수 또한 전달 가능하다.

#### 목록 3.5 최적화기 구성하기(최적화기 파라미터 설정)

```
model %>% compile(
  optimizer = optimizer_rmsprop(lr = 0.001),
  loss = "binary_crossentropy",
  metrics = c("accuracy")
)
```


#### 목록 3.6 사용자 정의를 한 손실과 메트릭 사용하기(최적화기 파라미터 설정)

```
model %>% compile(
  optimizer = optimizer_rmsprop(lr = 0.001),
  loss = loss_binary_crossentropy,
  metrics = metric_binary_accuracy
)
```

### 3.4.4 접근 방식 검증하기

전에 본 적이 없는 데이터에 대한 모델의 정확도를 훈련 중에 관측하기 위해 원래의 훈련 데이터에서 1만개 표본을 설정해 검증 집합을 작성한다.

#### 목록 3.7 검증 집합 따로 설정하기

```{r}
val_indices = 1:10000

x_val = x_train[val_indices, ]
partial_x_train = x_train[-val_indices, ]
y_val = y_train[val_indices]
partial_y_train = y_train[-val_indices]
```

#### 목록 3.8 모델 훈련하기

```{r}
model %>% compile(
  optimizer = "rmsprop",
  loss = "binary_crossentropy",
  metrics = c("accuracy")
)
history = model %>% fit(
  partial_x_train,
  partial_y_train,
  epochs = 20,
  batch_size = 512,
  validation_data = list(x_val, y_val)
)
```

`fit()`을 호출하면 `history` 객체를 반환한다는 점에 주의한다. 다음을 살펴보자.

```{r}
str(history)
```

`history`객체는 모델(`history$params`)뿐 아니라 관측되는 각 메트릭(`history$metrics`)에 대한 데이터를 저장하는 데 사용되는 파라미터를 포함한다.

`history`객체에는 에포크별로 훈련 계량 및 검증 계량을 시각화할 수 있는 `plot()`메서드가 있다.

```{r}
plot(history)
```

#### `plot()` 메서드를 사용한 훈련 내역

훈련 이력 객체의 `plot()` 메서드는 `ggplot2`를 사용하여 그래프를 그릴 수 있다(사용하지 않는 경우에는 기본 그래픽이 사용된다). 그림에는 지정된 메트릭과 손실이 모두 포함된다. 열 개 이상의 에포크가 있다면 매끄러운 선이 그려지게 된다. `plot()` 메서드의 다양한 인수를 사용하면, 이러한 동작을 모두 사용자 정의할 수 있다. 사용자 정의 시각화를 작성하려면, 이력에서 `as.data.frame()`메서드를 호출하여 각 계량에 대한 요소 및 학습 버전 검증을 포함한 데이터 프레임을 확보해야 한다.

```{r}
history_df = as.data.frame(history)
str(history_df)
```

훈련 손실은 모든 에포크마다 줄어들고, 훈련의 정확도는 증가한다. 이것이 경사 하강 최적화(손실이 최소가 되게끔 가중치를 갱신하는 과정)를 실행할 때 기대할 수 있는 점이다. 검증 손실과 정확도는 훈련 시와 다르다. 오히려 네 번째 에포크에서 가장 좋은 성능을 내는 것처럼 보인다. 이것이 과적합의 예가 된다. 훈련 데이터에서 더 잘 수행되는 모델이라고 해서 이전에는 전혀 본 적이 없는 데이터에서 더 잘 수행하는 모델이 된다고 보장되지는 못한다. 이를 과적합(overfitting)이라고 한다. 두 번째 에포크 이후에 훈련 데이터가 과도하게 최적화돼 있고, 훈련 데이터에만 특정된 표현을 학습하게 되어, 훈련 집합이 아닌 데이터에까지 일반화를 하지 못하게 되는 것이다.

이 경우, 과적합을 방지하기 위해 세 개 에포크 이후에 훈련을 중단할 수 있다. 일반적으로 과적합을 줄이기 위해 다양한 기법을 사용할 수 있다. 이에 대해서는 4장에서 다루게 된다.

네 개 에포크를 대상으로 삼아 밑바닥에서부터 새로운 망을 훈련한 후, 테스트 데이터를 사용하여 평가해본다.

#### 목록 3.9 모델을 밑바닥에서부터 재훈련하기

```{r}
# 필요한 경우 Keras 라이브러리를 먼저 불러옵니다.
??keras
clear_se
# tf$config$experimental$reset_memory_stats("GPU:0")

keras::k_clear_session()
keras

detach("package:tensorflow", unload = TRUE)
detach("package:keras", unload = TRUE)
```

```{r}
# # 혹시 이전 세션/그래프 남아있으면 비우기
keras::k_clear_session()
# tf$config$experimental$reset_memory_stats("GPU:0")

# 필요한 경우 Keras 라이브러리를 먼저 불러옵니다.
library(keras)

# Keras 세션을 지웁니다.
keras::backend::clear_session()

# 더 이상 사용하지 않는 모델 및 텐서 객체 제거
rm(list = ls())

# 가비지 컬렉션 실행
gc()


model = keras_model_sequential() %>% 
  layer_dense(units = 16, activation = "relu", input_shape = c(10000)) %>% 
  layer_dense(units = 16, activation = "relu") %>% 
  layer_dense(units = 1, activation = "sigmoid")

model %>%  compile(
  optimizer = "rmsprop",
  loss = "binary_crossentropy",
  metrics = c("accuracy")
)

model %>% fit(x_train, y_train, epochs = 4, batch_size = 256)
## 해당 코드는 Vram이 높은 상황에서 실행가능하다
# results = model %>% evaluate(x_test, y_test)
```

```{r}
eval_in_batches <- function(model, x, y, batch_size = 256) {
  n <- nrow(x)
  n_batches <- ceiling(n / batch_size)
  
  total_loss <- 0
  total_acc  <- 0
  total_n    <- 0
  
  for (b in seq_len(n_batches)) {
    idx_start <- (b - 1) * batch_size + 1
    idx_end   <- min(b * batch_size, n)
    idx <- idx_start:idx_end
    
    x_batch <- x[idx, , drop = FALSE]
    y_batch <- y[idx]
    
    metrics <- model %>% evaluate(
      x_batch, y_batch,
      verbose = 0
    )
    # keras::evaluate()는 named vector 반환 (loss, accuracy)
    batch_n <- length(idx)
    total_loss <- total_loss + metrics["loss"] * batch_n
    total_acc  <- total_acc  + metrics["accuracy"] * batch_n
    total_n    <- total_n + batch_n
  }
  
  c(
    loss     = as.numeric(total_loss / total_n),
    accuracy = as.numeric(total_acc / total_n)
  )
}

results <- eval_in_batches(model, x_test, y_test, batch_size = 256)
```

최종결과는 다음과 같다.

```{r}
results
```

### 3.4.5 훈련된 망을 사용해 신규 데이터에 대한 예측 생성하기

```{r}
model %>% predict(x_test[1:10, ])
```

여기서 망은 일부 표본(0.99 이상 0.01 이하)에서는 확신을 보이지만, 그 밖의 표본(0.6, 0.8)에서는 확신을 보이지 않음을 알 수 있다.

### 3.4.6 추가 실험

다음에 이어 나오는 실험들은 아직 개선을 해야 할 부분이 있지만, 상당히 합리적으로 아키텍처를 선택했다는 점을 확신하는 데는 도움을 줄 수 있다.

- 이 책에서는 은닉 계층 2개를 사용했다. 한 개 은닉 계층 또는 세 개 은닉 계층을 사용해 검증 및 테스트 정확도에 미치는 영향을 확인해 보자.

- 32 유닛이나 64 유닛 등과 같이 은닉 유닛이 적거나 많은 계층을 사용해보자.

- `binary_crossentropy` 대신 `mse`라는 손실 함수를 사용해보자.

- `relu` 대신 `tanh` 활성함수를 사용해보자.

### 3.4.7 결론

이 예제로부터 배워야 할 사항은 다음과 같다.

- 신경망에 텐서와 같은 것을 공급할 수 있으려면 원시 데이터에 대한 전처리 작업을 많이 해 둬야 한다. 단어 시퀀스는 이진 벡터로 부호화될 수 있지만, 다른 부호화 옵션도 있다.

- ReLU 활성화가 있는 조밀 계층 스택은 감성 분류를 비롯한 다양한 문제를 해결할 수 있으므로 자주 사용하게 될 것이다.

- 망은 이항 분류 문제(출력 클래스가 두 개)에서 하나의 유닛과 시그모이드 활성이 있는 조밀 계층으로 끝나야 한다. 망의 출력은 0과 1사이의 스칼라여야 하며, 확률을 부호화해야 한다.

- 이항 분류 문제와 같은 스칼라 시그모이드 출력을 사용하면, 손실 함수는 `binary_crossentropy`가 된다.

- `rmsprop`이라는 최적화기는 어떤 문제에도 충분히 대응할 수 있는 선택지이다. 걱정할 필요가 전혀 없다.

- 신경망이 훈련 데이터에 익숙해질수록 과적합되어 이전에는 볼 수 없었던 데이터에 대한 결과가 점점 악화된다. 따라서 훈련 집합의 외부에 있는 데이터의 성능을 항상 관찰해야 한다.


